{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day_076-Optimizer_HW.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oailnivek/ML100-Days/blob/master/homework/Day_076_Optimizer_HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "IfLhzitP_Gd6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 作業: \n",
        "    \n",
        "    (1)以, Adam, 為例, 調整 batch_size, epoch , 觀察accurancy, loss 的變化\n",
        "    \n",
        "    (2)以同一模型, 分別驗證 SGD, Adam, Rmsprop 的 accurancy"
      ]
    },
    {
      "metadata": {
        "id": "DoOVIOGR_Gd8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "#from keras.datasets import cifar10\n",
        "from keras.datasets import mnist \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import optimizers\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qYsXDmMeAzfI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 第一步： 選擇模型, 順序模型是多個網絡層的線性堆疊\n",
        "\n",
        "# 第二步： 構建網絡層\n",
        "\n",
        "# 第三步： 編譯\n",
        "\n",
        "# 第四步： 資料分割\n",
        "\n",
        "# 第五步： 訓練, 修正 model 參數\n",
        "\n",
        "# 第六步： 輸出"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yUVUKtgA_Gd_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(500, activation='relu', input_shape=(784,))) # 輸入層，28*28=784 \n",
        "\n",
        "    model.add(Dense(500, activation='relu')) # 隱藏層節點500個\n",
        "    model.add(Dense(500, activation='relu')) # 隱藏層節點500個\n",
        "    model.add(Dense(500, activation='relu')) # 隱藏層節點500個\n",
        "    \n",
        "    model.add(Dense(10, activation='softmax')) # 輸出結果是10個類別，所以維度是10\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NJVpMJ-w_GeD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "2b1bbd00-ba50-4015-ed97-5c8a84f247cc"
      },
      "cell_type": "code",
      "source": [
        "def model_summary():\n",
        "    model = create_model()\n",
        "    # 模型建立完成後，統計參數總量\n",
        "    print(\"Total Parameters：%d\" % model.count_params())\n",
        "\n",
        "    # 輸出模型摘要資訊\n",
        "    model.summary()\n",
        "\n",
        "model_summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Parameters：1149010\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_31 (Dense)             (None, 500)               392500    \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 500)               250500    \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 500)               250500    \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 500)               250500    \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 10)                5010      \n",
            "=================================================================\n",
            "Total params: 1,149,010\n",
            "Trainable params: 1,149,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LVfdsK8M_GeI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0af39897-4ff9-4a0a-ff06-5fa8fc02d7b4"
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "    SGD(隨機梯度下降) - Arguments\n",
        "    lr: float >= 0. Learning rate.\n",
        "    momentum: float >= 0. Parameter that accelerates SGD in the relevant direction and dampens oscillations.\n",
        "    decay: float >= 0. Learning rate decay over each update.\n",
        "    nesterov: boolean. Whether to apply Nesterov momentum.\n",
        "'''\n",
        "\n",
        "'''\n",
        "    RMSprop- Arguments\n",
        "    lr: float >= 0. Learning rate.\n",
        "    rho: float >= 0.\n",
        "    epsilon: float >= 0. Fuzz factor. If None, defaults to K.epsilon().\n",
        "    decay: float >= 0. Learning rate decay over each update.\n",
        "'''"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n    RMSprop- Arguments\\n    lr: float >= 0. Learning rate.\\n    rho: float >= 0.\\n    epsilon: float >= 0. Fuzz factor. If None, defaults to K.epsilon().\\n    decay: float >= 0. Learning rate decay over each update.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "JMrcKjGm_GeM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_data():\n",
        "    # 使用Keras自帶的mnist工具讀取數據（第一次需要聯網）\n",
        "    (X_train, y_train), (X_test, y_test) = mnist.load_data() \n",
        "\n",
        "    # 由於mist的輸入數據維度是(num, 28 , 28)， 這裡需要把後面的維度直接拼起來變成784維   \n",
        "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1] * X_train.shape[2])\n",
        "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2])  \n",
        "    Y_train = (numpy.arange(10) == y_train[:, None]).astype(int)\n",
        "    Y_test = (numpy.arange(10) == y_test[:, None]).astype(int)\n",
        "    \n",
        "    return X_train, Y_train, X_test, Y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B0UEao5F_GeO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Blas GEMM launch failed , 避免動態分配GPU / CPU, 出現問題\n",
        "import tensorflow as tf\n",
        "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
        "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Oos5jG35_GeS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class OptimizerTest:\n",
        "    def __init__(self, optimizer, batch_size, epochs):\n",
        "        self.model = create_model()\n",
        "        self.optimizer = optimizer\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def fit(self, input):\n",
        "        '''\n",
        "           宣告並設定\n",
        "           batch_size：對總的樣本數進行分組，每組包含的樣本數量\n",
        "           epochs ：訓練次數\n",
        "        ''' \n",
        "\n",
        "        X_train, Y_train = input\n",
        "\n",
        "        self.model.compile(\n",
        "            optimizer=self.optimizer,\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        return self.model.fit(\n",
        "            X_train,\n",
        "            Y_train,\n",
        "            batch_size=self.batch_size,\n",
        "            epochs=self.epochs,\n",
        "            shuffle=True,\n",
        "            verbose=0,\n",
        "            validation_split=0.3\n",
        "        )\n",
        "    \n",
        "    def evaluate(self, input):\n",
        "        X_test, Y_test = input\n",
        "\n",
        "        print('test set\\n')\n",
        "        scores = self.model.evaluate(\n",
        "            X_test,\n",
        "            Y_test,\n",
        "            batch_size=self.batch_size,\n",
        "            verbose=0\n",
        "        )\n",
        "        print ('The test loss is {}\\n'.format(scores))\n",
        "        result = self.model.predict(X_test, batch_size=200, verbose=0)\n",
        "\n",
        "        result_max = numpy.argmax(result, axis=1)\n",
        "        test_max = numpy.argmax(Y_test, axis=1)\n",
        "\n",
        "        result_bool = numpy.equal(result_max, test_max)\n",
        "        true_num = numpy.sum(result_bool)\n",
        "        print ('The accuracy of the model is {}'.format(true_num / len(result_bool)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7d0hofPHKbIP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot(history):\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
        "    \n",
        "    # Plot training & validation accuracy values\n",
        "    ax[0].plot(history.history['acc'])\n",
        "    ax[0].plot(history.history['val_acc'])\n",
        "    ax[0].set_title('Model accuracy')\n",
        "    ax[0].set_ylabel('Accuracy')\n",
        "    ax[0].set_xlabel('Epoch')\n",
        "    ax[0].legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "    # Plot training & validation loss values\n",
        "    ax[1].plot(history.history['loss'])\n",
        "    ax[1].plot(history.history['val_loss'])\n",
        "    ax[1].set_title('Model loss')\n",
        "    ax[1].set_ylabel('Loss')\n",
        "    ax[1].set_xlabel('Epoch')\n",
        "    ax[1].legend(['Train', 'Test'], loc='upper left')\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "obgvBYyn_Gec",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# history = model.fit(x, y, validation_split=0.25, epochs=50, batch_size=16, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fqWfwst-AeqK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1051
        },
        "outputId": "47c71b75-d315-42cb-ff31-f41243949c48"
      },
      "cell_type": "code",
      "source": [
        "X_train, Y_train, X_test, Y_test = get_data()\n",
        "\n",
        "for optimizer in ['adam', 'sgd', 'rmsprop']:\n",
        "    for batch_size in [100, 200, 300]:\n",
        "        for epochs in [10, 30]:\n",
        "            print('==========')\n",
        "            print('optimizer: {}\\nbatch_size: {}\\nepochs: {}'.format(optimizer, batch_size, epochs))\n",
        "            print('------------')\n",
        "            \n",
        "            test = OptimizerTest(\n",
        "                optimizer=optimizer,\n",
        "                batch_size=batch_size,\n",
        "                epochs=epochs\n",
        "            )\n",
        "\n",
        "            history = test.fit((X_train, Y_train))\n",
        "            test.evaluate((X_test, Y_test))\n",
        "            plot(history)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==========\n",
            "optimizer: adam\n",
            "batch_size: 100\n",
            "epochs: 10\n",
            "------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-44ba76b9eecc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m             )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-f919d16d95c9>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         )\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "eOrxz3pPV5Ru",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}