{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day_101_Final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kvzl/ML100-Days/blob/master/midterm/Day_101_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "bAA6CjuecrPp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 機器學習百日馬拉松 期末考"
      ]
    },
    {
      "metadata": {
        "id": "JBw8_xyPcMtO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 取得資料"
      ]
    },
    {
      "metadata": {
        "id": "VaqimfuccQgG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 連接雲端硬碟\n",
        "\n",
        "用來取得放在雲端硬碟的 Kaggle 憑證"
      ]
    },
    {
      "metadata": {
        "id": "rWQIVEEqeB1X",
        "colab_type": "code",
        "outputId": "55bdb645-046e-4623-d953-da7c29ed9012",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fD8aEUaCcTVE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 從 Kaggle 下載、解壓縮資料"
      ]
    },
    {
      "metadata": {
        "id": "6gh-Cc-scLrD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -rf ~/.kaggle && mkdir ~/.kaggle && cp ./gdrive/My\\ Drive/個人/keys/kaggle.json ~/.kaggle/kaggle.json && chmod 600 ~/.kaggle/kaggle.json && kaggle competitions download -c ml100marathon-final-exam && unzip image_data.zip\n",
        "!mkdir weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2dqjb9BSi22m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 引入所需函式庫"
      ]
    },
    {
      "metadata": {
        "id": "N9SP7ZxicU7J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "import os\n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from PIL import Image\n",
        "import imgaug as ia\n",
        "from imgaug  import augmenters as iaa\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_HzvkarqhEmc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 常數"
      ]
    },
    {
      "metadata": {
        "id": "XlTftp1B9OV6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "flower_map = {\n",
        "    0: 'daisy',\n",
        "    1: 'dandelion',\n",
        "    2: 'rose',\n",
        "    3: 'sunflower',\n",
        "    4: 'tulip'\n",
        "}\n",
        "\n",
        "num_classes = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZqRrPQKwbiKa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 輔助函式"
      ]
    },
    {
      "metadata": {
        "id": "4vlXw9gsbm40",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 畫出訓練過程"
      ]
    },
    {
      "metadata": {
        "id": "cAqrVQ6D-l1L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_train_history(history):\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
        "    \n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    acc = history.history['acc']\n",
        "    val_acc = history.history['val_acc']\n",
        "    \n",
        "    ax[0].plot(loss, label='train')\n",
        "    ax[0].plot(val_loss, label='test')\n",
        "    ax[0].set_ylabel('Loss')\n",
        "    ax[0].legend()\n",
        "    \n",
        "    ax[1].plot(acc, label='train')\n",
        "    ax[1].plot(val_acc, label='test')\n",
        "    ax[1].set_ylabel('Accuracy')\n",
        "    ax[1].legend()\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DAAsuKC9b248",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 排列顯示圖片"
      ]
    },
    {
      "metadata": {
        "id": "tb5alcfxb1vv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def show_images(images, labels=None, size=(5, 4), start=0):\n",
        "    row, col = size\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for i in range(row):\n",
        "        for j in range(col):\n",
        "            idx = (col * i) + j\n",
        "            plt.subplot(col, row, idx + 1)\n",
        "            plt.imshow(images[start + idx])\n",
        "            if labels is not None:\n",
        "                plt.title(flower_map[np.argmax(labels[start + idx])])\n",
        "            plt.axis('off')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "20WnhFJrgh3-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 將圖片轉為陣列"
      ]
    },
    {
      "metadata": {
        "id": "xt20bGW7ghFL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def image_to_array(filename):\n",
        "    return np.asarray(Image.open(filename, 'r'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RtB55MdZbwHV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 資料處理"
      ]
    },
    {
      "metadata": {
        "id": "9Xe0NHMmbyAi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def normalize(x):\n",
        "    x = np.array(x).astype('float32') / 255\n",
        "    return x\n",
        "\n",
        "\n",
        "def resize(images, size=(300, 300)):\n",
        "    width, height = size\n",
        "    \n",
        "    seq = iaa.Sequential([\n",
        "        iaa.PadToFixedSize(width, height),\n",
        "        iaa.CropToFixedSize(width, height)\n",
        "    ])\n",
        "    \n",
        "    return seq.augment_images(images)\n",
        "\n",
        "\n",
        "def data_augment(x, y):\n",
        "    seq = iaa.Sequential([\n",
        "        iaa.Fliplr(0.5),\n",
        "        iaa.Crop(percent=(0, 0.1)),\n",
        "        iaa.Sometimes(0.5,\n",
        "            iaa.GaussianBlur(sigma=(0, 0.5))\n",
        "        ),\n",
        "        iaa.ContrastNormalization((0.75, 1.5)),\n",
        "        iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
        "        iaa.Affine(\n",
        "            scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
        "            translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
        "            rotate=(-25, 25),\n",
        "            shear=(-8, 8)\n",
        "        )\n",
        "    ], random_order=True)\n",
        "\n",
        "    x_aug = seq.augment_images(x)\n",
        "    x += x_aug\n",
        "    y += y\n",
        "    \n",
        "    return x, y\n",
        "\n",
        "def data_augment_idg(x):\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "    datagen.fit(x)\n",
        "    \n",
        "    return datagen\n",
        "\n",
        "\n",
        "def preprocess(images, labels, image_size, data_augmentation='idg'):\n",
        "    def transform(x, y):\n",
        "        x = resize(x, size=image_size)\n",
        "        x = normalize(x)\n",
        "        y = to_categorical(np.array(y))\n",
        "        \n",
        "        return x, y\n",
        "\n",
        "    x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.3)\n",
        "\n",
        "    x_train, y_train = transform(x_train, y_train)\n",
        "\n",
        "    if data_augmentation == 'ia':\n",
        "        x_train, y_train = data_augment(x_train, y_train)\n",
        "        datagen = None\n",
        "\n",
        "    elif data_augmentation == 'idg':\n",
        "        datagen = data_augment_idg(x_train)\n",
        "   \n",
        "    x_test, y_test = transform(x_test, y_test)\n",
        "    \n",
        "    return (x_train, y_train), (x_test, y_test), datagen"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xC23tfWQcEaz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 讀取訓練資料"
      ]
    },
    {
      "metadata": {
        "id": "VPV8l9QaNz7X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    images, labels = [], []\n",
        "    \n",
        "    for idx, flower in flower_map.items():\n",
        "        name = os.path.basename(flower)\n",
        "        path = 'train/%s/*' % name\n",
        "        \n",
        "        for filename in glob.iglob(path):\n",
        "            images.append(image_to_array(filename))\n",
        "            labels.append(idx)\n",
        "\n",
        "    return images, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SiFykHyu5azG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 讀取所有測試編號"
      ]
    },
    {
      "metadata": {
        "id": "MPv5euKM5dgS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_test_ids():\n",
        "    return np.array([os.path.basename(id).split('.')[0] for id in glob.iglob('test/*.jpg')])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4dbOrZxehSp3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 讀取測試資料"
      ]
    },
    {
      "metadata": {
        "id": "tIGJCHIThQdf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_test_data(ids, image_size, batch_size=10):\n",
        "    for batch_ids in np.split(ids, len(ids) / batch_size):\n",
        "        x = [image_to_array('test/%s.jpg' % id) for id in batch_ids]        \n",
        "        x = resize(x, size=image_size)        \n",
        "        x = normalize(x)\n",
        "        \n",
        "        yield x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zeLEvEMRgEJb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 評估模型"
      ]
    },
    {
      "metadata": {
        "id": "jwMjh83ogD2j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(image_size, batch_size=5):\n",
        "    ids = np.array([os.path.basename(id).split('.')[0] for id in glob.iglob('test/*.jpg')])\n",
        "    gen = load_test_data(ids, image_size, batch_size)\n",
        "\n",
        "    return model.predict_generator(gen, \n",
        "                         steps=math.ceil(len(ids) / batch_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OnAD7o7nc_bZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 取得 Callbacks"
      ]
    },
    {
      "metadata": {
        "id": "TjDqoa9MlVO1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_callbacks(name='', es=True, es_patience=5):\n",
        "    file_name = './weights/weights.%s-{epoch:02d}-{loss:.2f}-{val_loss:.2f}.hdf5' % name\n",
        "        \n",
        "    red_lr = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.1)\n",
        "    \n",
        "    model_cp = ModelCheckpoint(file_name,\n",
        "                               monitor='val_loss',\n",
        "                               verbose=1,\n",
        "                               save_best_only=True,\n",
        "                               period=3)\n",
        "    \n",
        "    callbacks = [red_lr, model_cp]\n",
        "    \n",
        "    if es:\n",
        "        es = EarlyStopping(monitor='val_loss',\n",
        "                           min_delta=0,\n",
        "                           patience=es_patience,\n",
        "                           verbose=1, mode='auto', baseline=None, restore_best_weights=True)\n",
        "        callbacks.append(es)\n",
        "    \n",
        "    return callbacks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-aWmV0swdcHl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 將資料轉成提交用的格式"
      ]
    },
    {
      "metadata": {
        "id": "gFOFIRnhGbOP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_submit(x, y):\n",
        "    header = np.array([['id', 'flower_class']])\n",
        "    arr = np.transpose(np.array([x, y.astype('<U32')]))\n",
        "    return np.insert(arr, 0, ['id', 'flower_class']).reshape(2001, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "njdOb_YBdyds",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 將儲存的權重複製到雲端硬碟"
      ]
    },
    {
      "metadata": {
        "id": "De5yhUVSvw71",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp weights/weights.*.hdf5 gdrive/My\\ Drive/Models/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z18ZYIqk7tb7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 將儲存在雲端硬碟的權重複製到本地"
      ]
    },
    {
      "metadata": {
        "id": "WG4Hu1bu7mqq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp gdrive/My\\ Drive/Models/weights.*.hdf5 weights/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E-YB87-cd26P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 讀取指定 model"
      ]
    },
    {
      "metadata": {
        "id": "DK1DfdpndxwX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def recover_model(name):\n",
        "    model = tf.keras.models.load_model('weights/%s.hdf5' % name)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w40p-Vlwc1F2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 訓練模型"
      ]
    },
    {
      "metadata": {
        "id": "LJssIZBfc3UX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 自訂模型"
      ]
    },
    {
      "metadata": {
        "id": "11W35YDSUXCh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "images, labels = load_data()\n",
        "(x_train, y_train), (x_test, y_test), datagen = preprocess(images, labels, image_size=(224, 224), data_augmentation='idg')\n",
        "\n",
        "print((x_train.shape), (y_train.shape))\n",
        "print((x_test.shape), (y_test.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QRv-43JYPH_b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "show_images(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0nuxwOFM51-3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_custom_cnn():\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Conv2D(32, (5,5), padding='Same', activation='relu', input_shape=x_train.shape[1:]),\n",
        "        layers.MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "        layers.Conv2D(64, (3,3), padding='Same', activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
        "\n",
        "        layers.Conv2D(96, (3,3), padding='Same', activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
        "\n",
        "        layers.Conv2D(96, (3,3), padding='Same', activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(512),\n",
        "        layers.Activation('relu'),\n",
        "        layers.Dense(5, activation='softmax'),\n",
        "    ])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xYIPGBaf7owt",
        "colab_type": "code",
        "outputId": "3e548641-fe8b-4bb1-e667-4f9ace3c6781",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "cell_type": "code",
      "source": [
        "build_custom_cnn().summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 224, 224, 32)      2432      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 112, 112, 64)      18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 56, 56, 96)        55392     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 28, 28, 96)        83040     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 96)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 18816)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               9634304   \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 2565      \n",
            "=================================================================\n",
            "Total params: 9,796,229\n",
            "Trainable params: 9,796,229\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cEsujya_7vfL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "custom_cnn = build_custom_cnn()\n",
        "optimizer = tf.keras.optimizers.Adam(lr=1e-3)\n",
        "custom_cnn.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lbCtGxzQSdGG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2908
        },
        "outputId": "0b03ed1e-836f-45e1-a816-155cef431bca"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "\n",
        "history = custom_cnn.fit_generator(\n",
        "    datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "    epochs=50,\n",
        "    validation_data=(x_test, y_test),\n",
        "    verbose=1,\n",
        "    steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "    callbacks=get_callbacks('custom_cnn', es=False)\n",
        ")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "847/847 [==============================] - 1s 1ms/sample - loss: 0.8331 - acc: 0.6800\n",
            "16/16 [==============================] - 25s 2s/step - loss: 0.7522 - acc: 0.7110 - val_loss: 0.8262 - val_acc: 0.6800\n",
            "Epoch 2/50\n",
            "847/847 [==============================] - 1s 1ms/sample - loss: 0.8357 - acc: 0.6800\n",
            "16/16 [==============================] - 24s 1s/step - loss: 0.7533 - acc: 0.7136 - val_loss: 0.8286 - val_acc: 0.6800\n",
            "Epoch 3/50\n",
            "847/847 [==============================] - 1s 1ms/sample - loss: 0.8361 - acc: 0.6800\n",
            "\n",
            "Epoch 00003: val_loss improved from inf to 0.82885, saving model to ./weights/weights.custom_cnn-03-0.74-0.83.hdf5\n",
            "16/16 [==============================] - 24s 1s/step - loss: 0.7483 - acc: 0.7126 - val_loss: 0.8288 - val_acc: 0.6800\n",
            "Epoch 4/50\n",
            "847/847 [==============================] - 1s 1ms/sample - loss: 0.8372 - acc: 0.6812\n",
            "16/16 [==============================] - 24s 2s/step - loss: 0.7433 - acc: 0.7115 - val_loss: 0.8299 - val_acc: 0.6812\n",
            "Epoch 5/50\n",
            "847/847 [==============================] - 1s 1ms/sample - loss: 0.8374 - acc: 0.6824\n",
            "16/16 [==============================] - 24s 2s/step - loss: 0.7474 - acc: 0.7090 - val_loss: 0.8301 - val_acc: 0.6824\n",
            "Epoch 6/50\n",
            "847/847 [==============================] - 1s 1ms/sample - loss: 0.8362 - acc: 0.6836\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.82885 to 0.82881, saving model to ./weights/weights.custom_cnn-06-0.74-0.83.hdf5\n",
            "16/16 [==============================] - 24s 2s/step - loss: 0.7411 - acc: 0.7075 - val_loss: 0.8288 - val_acc: 0.6836\n",
            "Epoch 7/50\n",
            "847/847 [==============================] - 1s 1ms/sample - loss: 0.8375 - acc: 0.6824\n",
            "16/16 [==============================] - 24s 2s/step - loss: 0.7472 - acc: 0.7065 - val_loss: 0.8301 - val_acc: 0.6824\n",
            "Epoch 8/50\n",
            "847/847 [==============================] - 1s 1ms/sample - loss: 0.8385 - acc: 0.6848\n",
            "16/16 [==============================] - 24s 2s/step - loss: 0.7502 - acc: 0.7100 - val_loss: 0.8309 - val_acc: 0.6848\n",
            "Epoch 9/50\n",
            "847/847 [==============================] - 1s 2ms/sample - loss: 0.8355 - acc: 0.6871\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.82881 to 0.82809, saving model to ./weights/weights.custom_cnn-09-0.74-0.83.hdf5\n",
            "16/16 [==============================] - 24s 2s/step - loss: 0.7417 - acc: 0.7100 - val_loss: 0.8281 - val_acc: 0.6871\n",
            "Epoch 10/50\n",
            "847/847 [==============================] - 1s 1ms/sample - loss: 0.8347 - acc: 0.6919\n",
            "16/16 [==============================] - 24s 2s/step - loss: 0.7448 - acc: 0.7060 - val_loss: 0.8273 - val_acc: 0.6919\n",
            "Epoch 11/50\n",
            "847/847 [==============================] - 1s 1ms/sample - loss: 0.8356 - acc: 0.6895\n",
            "16/16 [==============================] - 24s 2s/step - loss: 0.7477 - acc: 0.7055 - val_loss: 0.8281 - val_acc: 0.6895\n",
            "Epoch 12/50\n",
            "847/847 [==============================] - 1s 1ms/sample - loss: 0.8353 - acc: 0.6895\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.82809 to 0.82783, saving model to ./weights/weights.custom_cnn-12-0.74-0.83.hdf5\n",
            "16/16 [==============================] - 25s 2s/step - loss: 0.7366 - acc: 0.7171 - val_loss: 0.8278 - val_acc: 0.6895\n",
            "Epoch 13/50\n",
            "847/847 [==============================] - 1s 1ms/sample - loss: 0.8350 - acc: 0.6895\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "16/16 [==============================] - 24s 2s/step - loss: 0.7381 - acc: 0.7100 - val_loss: 0.8275 - val_acc: 0.6895\n",
            "Epoch 14/50\n",
            "847/847 [==============================] - 1s 1ms/sample - loss: 0.8350 - acc: 0.6907\n",
            "16/16 [==============================] - 24s 2s/step - loss: 0.7414 - acc: 0.7100 - val_loss: 0.8275 - val_acc: 0.6907\n",
            "Epoch 15/50\n",
            "847/847 [==============================] - 1s 1ms/sample - loss: 0.8351 - acc: 0.6907\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.82783 to 0.82763, saving model to ./weights/weights.custom_cnn-15-0.73-0.83.hdf5\n",
            "16/16 [==============================] - 24s 2s/step - loss: 0.7263 - acc: 0.7227 - val_loss: 0.8276 - val_acc: 0.6907\n",
            "Epoch 16/50\n",
            "847/847 [==============================] - 1s 2ms/sample - loss: 0.8348 - acc: 0.6907\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "16/16 [==============================] - 24s 2s/step - loss: 0.7414 - acc: 0.7075 - val_loss: 0.8273 - val_acc: 0.6907\n",
            "Epoch 17/50\n",
            "847/847 [==============================] - 1s 1ms/sample - loss: 0.8348 - acc: 0.6907\n",
            "16/16 [==============================] - 24s 1s/step - loss: 0.7268 - acc: 0.7257 - val_loss: 0.8273 - val_acc: 0.6907\n",
            "Epoch 18/50\n",
            "847/847 [==============================] - 1s 1ms/sample - loss: 0.8347 - acc: 0.6907\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.82763 to 0.82730, saving model to ./weights/weights.custom_cnn-18-0.74-0.83.hdf5\n",
            "16/16 [==============================] - 24s 2s/step - loss: 0.7323 - acc: 0.7115 - val_loss: 0.8273 - val_acc: 0.6907\n",
            "Epoch 19/50\n",
            "847/847 [==============================] - 1s 1ms/sample - loss: 0.8347 - acc: 0.6907\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
            "16/16 [==============================] - 24s 1s/step - loss: 0.7404 - acc: 0.7095 - val_loss: 0.8273 - val_acc: 0.6907\n",
            "Epoch 20/50\n",
            "847/847 [==============================] - 1s 2ms/sample - loss: 0.8347 - acc: 0.6907\n",
            "16/16 [==============================] - 24s 1s/step - loss: 0.7303 - acc: 0.7120 - val_loss: 0.8273 - val_acc: 0.6907\n",
            "Epoch 21/50\n",
            "847/847 [==============================] - 1s 1ms/sample - loss: 0.8347 - acc: 0.6907\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.82730\n",
            "16/16 [==============================] - 24s 1s/step - loss: 0.7481 - acc: 0.7105 - val_loss: 0.8273 - val_acc: 0.6907\n",
            "Epoch 22/50\n",
            "847/847 [==============================] - 1s 1ms/sample - loss: 0.8347 - acc: 0.6907\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
            "16/16 [==============================] - 24s 2s/step - loss: 0.7456 - acc: 0.7085 - val_loss: 0.8273 - val_acc: 0.6907\n",
            "Epoch 23/50\n",
            "847/847 [==============================] - 1s 1ms/sample - loss: 0.8347 - acc: 0.6907\n",
            "16/16 [==============================] - 24s 2s/step - loss: 0.7294 - acc: 0.7105 - val_loss: 0.8273 - val_acc: 0.6907\n",
            "Epoch 24/50\n",
            "847/847 [==============================] - 1s 1ms/sample - loss: 0.8347 - acc: 0.6907\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.82730\n",
            "16/16 [==============================] - 24s 2s/step - loss: 0.7313 - acc: 0.7141 - val_loss: 0.8273 - val_acc: 0.6907\n",
            "Epoch 25/50\n",
            "847/847 [==============================] - 1s 1ms/sample - loss: 0.8347 - acc: 0.6907\n",
            "\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
            "16/16 [==============================] - 24s 2s/step - loss: 0.7337 - acc: 0.7070 - val_loss: 0.8273 - val_acc: 0.6907\n",
            "Epoch 26/50\n",
            "847/847 [==============================] - 1s 2ms/sample - loss: 0.8347 - acc: 0.6907\n",
            "16/16 [==============================] - 24s 2s/step - loss: 0.7384 - acc: 0.7024 - val_loss: 0.8273 - val_acc: 0.6907\n",
            "Epoch 27/50\n",
            "847/847 [==============================] - 1s 2ms/sample - loss: 0.8347 - acc: 0.6907\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.82730\n",
            "16/16 [==============================] - 24s 2s/step - loss: 0.7448 - acc: 0.7080 - val_loss: 0.8273 - val_acc: 0.6907\n",
            "Epoch 28/50\n",
            "847/847 [==============================] - 1s 2ms/sample - loss: 0.8347 - acc: 0.6907\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
            "16/16 [==============================] - 24s 2s/step - loss: 0.7293 - acc: 0.7212 - val_loss: 0.8273 - val_acc: 0.6907\n",
            "Epoch 29/50\n",
            "847/847 [==============================] - 1s 1ms/sample - loss: 0.8347 - acc: 0.6907\n",
            "16/16 [==============================] - 24s 2s/step - loss: 0.7466 - acc: 0.7055 - val_loss: 0.8273 - val_acc: 0.6907\n",
            "Epoch 30/50\n",
            "847/847 [==============================] - 1s 1ms/sample - loss: 0.8347 - acc: 0.6907\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.82730\n",
            "16/16 [==============================] - 24s 2s/step - loss: 0.7307 - acc: 0.7186 - val_loss: 0.8273 - val_acc: 0.6907\n",
            "Epoch 31/50\n",
            "847/847 [==============================] - 1s 2ms/sample - loss: 0.8347 - acc: 0.6907\n",
            "\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
            "16/16 [==============================] - 24s 2s/step - loss: 0.7361 - acc: 0.7110 - val_loss: 0.8273 - val_acc: 0.6907\n",
            "Epoch 32/50\n",
            "847/847 [==============================] - 1s 2ms/sample - loss: 0.8347 - acc: 0.6907\n",
            "16/16 [==============================] - 24s 2s/step - loss: 0.7486 - acc: 0.7055 - val_loss: 0.8273 - val_acc: 0.6907\n",
            "Epoch 33/50\n",
            "847/847 [==============================] - 1s 1ms/sample - loss: 0.8347 - acc: 0.6907\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.82730\n",
            "16/16 [==============================] - 24s 2s/step - loss: 0.7381 - acc: 0.7045 - val_loss: 0.8273 - val_acc: 0.6907\n",
            "Epoch 34/50\n",
            "847/847 [==============================] - 1s 1ms/sample - loss: 0.8347 - acc: 0.6907\n",
            "\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
            "16/16 [==============================] - 24s 2s/step - loss: 0.7437 - acc: 0.7161 - val_loss: 0.8273 - val_acc: 0.6907\n",
            "Epoch 35/50\n",
            "847/847 [==============================] - 1s 2ms/sample - loss: 0.8347 - acc: 0.6907\n",
            "16/16 [==============================] - 24s 2s/step - loss: 0.7413 - acc: 0.7115 - val_loss: 0.8273 - val_acc: 0.6907\n",
            "Epoch 36/50\n",
            "847/847 [==============================] - 1s 1ms/sample - loss: 0.8347 - acc: 0.6907\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.82730\n",
            "16/16 [==============================] - 24s 1s/step - loss: 0.7376 - acc: 0.7171 - val_loss: 0.8273 - val_acc: 0.6907\n",
            "Epoch 37/50\n",
            " 6/16 [==========>...................] - ETA: 14s - loss: 0.7637 - acc: 0.7031"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-8409be1d72b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'custom_cnn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m       \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[0;34m(output_generator, mode)\u001b[0m\n\u001b[1;32m    256\u001b[0m   \u001b[0;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;31m# Returning `None` will trigger looping to stop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "HBiMyY-WINmJ",
        "colab_type": "code",
        "outputId": "ea7e66bc-6c56-4807-f4fd-05898d23674e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "cell_type": "code",
      "source": [
        "plot_train_history(history)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAAEYCAYAAABBfQDEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xd4FNX6wPHv2U3vFUISQkLovYQu\niqKCKDYUAVFBr1iu5V57ufafvV0bKCpiAwvYLgKiSBGpoXeSACEFSCO9Z8/vjwkxQIAI2Z0k+36e\nZ57dnTkz+25GNy8n57xHaa0RQgghhBBCGCxmByCEEEIIIURjIgmyEEIIIYQQtUiCLIQQQgghRC2S\nIAshhBBCCFGLJMhCCCGEEELUIgmyEEIIIYQQtUiCLIQQQgghRC2SIAshhBBCCFGLJMhCCCGEEELU\n4mKvCyulZgCXARla6251HPcHvgCiquN4TWv9yemuGxISoqOjoxs4WiGEsL/169dnaa1DzY6jIch3\nsRCiKarv97DdEmRgJvAu8NlJjv8T2KG1Hq2UCgV2K6W+1FqXn+qi0dHRxMfHN2ykQgjhAEqpZLNj\naCjyXSyEaIrq+z1styEWWuvlQM6pmgC+SikF+FS3rbRXPEIIIYQQQtSHmWOQ3wU6A+nAVuBerbWt\nroZKqSlKqXilVHxmZqYjYxRCCCGEEE7GzAR5BLAJCAd6Ae8qpfzqaqi1nq61jtNax4WGNovhe0II\nIYQQopGy5xjk05kMvKS11kCiUmof0AlYa2JMQgg7qaioIDU1ldLSUrNDsTsPDw8iIyNxdXU1OxSH\ncpZ77Kz3VwhnYmaCfAAYDvyhlGoJdAT2mhiPEMKOUlNT8fX1JTo6GmPqQfOktSY7O5vU1FRiYmLM\nDsehnOEeO/P9FcKZ2G2IhVJqNrAK6KiUSlVK3aKUul0pdXt1k+eAwUqprcBi4GGtdZa94hFCmKu0\ntJTg4OBmmzgdpZQiODi42fei1sUZ7rEz318hnIndepC11uNPczwduNhe7y+EaHyac+JUm7N8zro4\nw2d3hs8ohLOTlfSEEEIIIYSoxSkS5Nd+2c2bv+4xOwwhhIlyc3OZOnXq3z5v1KhR5Obm2iEi0dDk\nHgvR/CVmFPL+siRunrmOKpu22/s4RYK8JS2PJbszzA5DCGGikyVPlZWnXp9o/vz5BAQE2Css0YDk\nHgvR/FTZNGv35fDC/J1c8NpSLnxjGS8t2EVGQSlZhWV2e18zq1g4TESABzvS88wOQwhR7Zn/bWdH\nen6DXrNLuB9Pje560uOPPPIISUlJ9OrVC1dXVzw8PAgMDGTXrl3s2bOHK6+8kpSUFEpLS7n33nuZ\nMmUK8NeSyoWFhVxyySWcc845rFy5koiICH788Uc8PT0b9HM0F3KPhRBnqqiskj8SMvl1Rwa/7zrM\nkeIKXK2KQbEhTB4SzfDOLQkPsO//l06RIIf7e5JVWE5pRRUerlazwxFCmOCll15i27ZtbNq0iaVL\nl3LppZeybdu2mlJdM2bMICgoiJKSEvr168eYMWMIDg4+5hoJCQnMnj2bDz/8kLFjxzJ37lwmTpxo\nxscRdZB7LETTlVdSwc9bDvLrjkP8mZRNeaUNPw8XLujUgou6hHFuhxB8PRxXe9w5EuTqf2UczCsl\nJsTb5GiEEKfqBXSU/v37H1PH9u233+b7778HICUlhYSEhBOSp5iYGHr16gVA37592b9/v8PibWrk\nHgsh6iO7sIyPV+zj81XJFJRV0jrIk4kD2nBhlxb0iw7C1WrOaGCnSpDTc0skQRZCAODt/dd3wdKl\nS/ntt99YtWoVXl5eDBs2rM46t+7u7jXPrVYrJSUlDolVnBm5x0I0XofySpm+fC+z1iZTVmljVLdW\n3H5eLN0i/BpFKUWnSJAjqhPktFz5ohPCWfn6+lJQUFDnsby8PAIDA/Hy8mLXrl2sXr3awdGJhiD3\nWIjG70B2MdOWJTF3fSpVWnNlrwjuGBZLuxY+Zod2DKdIkFv6u6OU0YMshHBOwcHBDBkyhG7duuHp\n6UnLli1rjo0cOZL333+fzp0707FjRwYOHGhipOJMyT0WovFKzChg6pIkftycjlUpro2L5PbzYmkd\n5GV2aHVyigTZ3cVKqI+7JMhCOLlZs2bVud/d3Z0FCxbUeezoGNSQkBC2bdtWs/+BBx5o8PjE2ZN7\nLIT9FJVVMnvtAdbtz8HH3RV/T1f8PF3w93Q9ZvOr9Twxo5CpSxNZsO0QHi5WJg2OZsq5bWnp52H2\nxzklp0iQwRiHnJ574ngzIYQQQghxcnklFXy2cj8z/tzHkeIKYkK8Ka+0kVdSQWHZqeuMA/i6u/DP\nYe2YPCSaYB/307ZvDJwmQY4I8GTnwYatySmEEEII0VwdX2FieKcW/POCdvSJCqxpU1llo6C0kryS\nimO2/FLj0dPVytV9IvH3dFyJtobgNAlyeIAHv+08jNa6UcyOFEIIIYRojOqqMHHn+bF0Dfc/oa2L\n1UKgtxuB3m4mRGo/TpQge1JWaSOnqLzJdO8LIcTZUkqNBN4CrMBHWuuXjjv+JnB+9UsvoIXWWtZd\nFsIJpeQYFSbmxBsVJq7oFc6dw9o1ugoTjuBUCTJAem6pJMhCCKeglLIC7wEXAanAOqXUT1rrHUfb\naK3/Xav93UBvhwcqhHAom02TW1JBdmEZmYVlZBeWs2R3Bj9uahoVJhzBaRLk2rWQu0ee+CcCIYRo\nhvoDiVrrvQBKqa+AK4AdJ2k/HnjKQbEJIc5QlU1TXF5JSXkVReVVNc+Lq58XVz8vKK0kq7CM7MIy\nsgrLjedF5eQUlVNl08dc09PVqDBx69C2hPk37goTjuA0CXLt1fSEEM4nNzeXWbNmceedd/7tc//7\n3/8yZcoUvLyaXG9KBJBS63UqMKCuhkqpNkAM8PvJLqaUmgJMAYiKimq4KBuIk95j4SR2HsznlYW7\nWJmUTVmlrd7nebpaCfF1I9jbnchAL3q1DiDEx51gH7djHiMCPPF2d5q08LSc5icR6OWKh6tFEmQh\nnFRubi5Tp0494+Rp4sSJzT15GgfM0VpXnayB1no6MB0gLi5On6ydWeQei+boYF4Jry/aw9wNqfi6\nuzC+fxQBXq54uVnxcnOpfrTi6eaCt5sVz1r7fdxdJOk9Q07zU1NKGbWQ8yRBFsJ0Cx6BQ1sb9pph\n3eGSl056+JFHHiEpKYlevXpx0UUX0aJFC7755hvKysq46qqreOaZZygqKmLs2LGkpqZSVVXFE088\nweHDh0lPT+f8888nJCSEJUuWNGzc9pUGtK71OrJ6X13GAf9ssHeWeyzEWckvrWDa0iRmrNiH1nDr\n0LbcOSyWAK/mVS2isXKaBBmMcchpsliIEE7ppZdeYtu2bWzatIlFixYxZ84c1q5di9aayy+/nOXL\nl5OZmUl4eDg///wzAHl5efj7+/PGG2+wZMkSQkJCTP4Uf9s6oL1SKgYjMR4HTDi+kVKqExAIrHJs\neA3LSe+xaIQy8kvZn11M13C/v92DW15p48s1yby9OIEjxRVc2Suc+y/u6NQT5szgVAlyuL8nuw5l\nmB2GEOIUvYCOsGjRIhYtWkTv3kbBhsLCQhISEhg6dCj3338/Dz/8MJdddhlDhw41Nc6zpbWuVErd\nBfyCUeZthtZ6u1LqWSBea/1TddNxwFda64YbNiH3WDipjQeOMHnmOnKLK7Ao6BTmR++oAHpHBdI7\nKoCYYG8slhPXY9Ba8/PWg7yycDcHcooZHBvMY6M60y1CCguYwbkS5ABPMgvKKKuswt3FanY4QgiT\naK159NFHue222044tmHDBubPn89//vMfhg8fzpNPPmlChA1Haz0fmH/cviePe/20I2NyBGe6x6Lx\nWL4nk9u/WE+Ijzv/d2U39hwqYGNKLj9tSufLNQcA8Pd0pVfrgJqkuVdkADsP5fPi/J1sTs2jU5gv\nMyf347wOobKwmYmcLEE2ypYcyiulTbC3ydEIIRzJ19eXgoICAEaMGMETTzzB9ddfj4+PD2lpabi6\nulJZWUlQUBATJ04kICCAjz766Jhz5c/vjZvcY2GmeVvS+ffXm4gN9eGzm/vTws8DehjHbDZNUmYh\nGw/ksjHlCBsP5PLW4gRq/80mzM+DV6/pwdV9IrHW0cPs9CpK4NA2SN8A6Rvh8Ha4dQlY7ZPKOlWC\nXLsWsiTIQjiX4OBghgwZQrdu3bjkkkuYMGECgwYNAsDHx4cvvviCxMREHnzwQSwWC66urkybNg2A\nKVOmMHLkSMLDw2UCVyMm91iY5fPVyTz54zbi2gTy0U398Pd0Pea4xaJo39KX9i19GdvPmDdbWFbJ\nlpRcNqbk4uVmZXz/KDxcG/Cv2zYb2CrApYEXR7PZoLIE3OyYR1WWQ8Z2IxFO2wDpmyBjBxwtsuPd\nAiL6QGkueNvnH7WqIYecOUJcXJyOj48/o3P3ZxUx7LWlvHZtT67pG9nAkQkhTmXnzp107tzZ7DAc\npq7Pq5Rar7WOMymkBlXXd7Ez3WNn+qzi5LTWvL04kTd/28PwTi14d0IfPN1MHsJZmAEbPoP1n0JB\nOkT0hZhzIXootO4Prp5/73paQ+Zu2Lcc9i+H/X9CSQ74tITg9hBSvQW3h5B2ENAGLPX4GZQXQcEh\nKDj412POvure4W1QVW608wyE8D4Q3tvYIvqAbys4w+En9f0edqoe5KMrw0gtZCGEEEKcDZtN8+y8\nHcxcuZ+r+0Tw8pgeuFot5gSjNexfAfEfw855Rs9x9FDoegUkr4I/Xoflr4LV3UiSo4dCzFCIiAMX\ntxOvlbO3OiH+A/b9AUXVBQ78W0PHSyAoxkhmsxJgxw9QcuSv861uEBRrJMvB7cE7FAoPH5cMH4Ky\nvBM/h7sftOoJA+/4KyEOaHPGyfDZcKoE2cPVSoiPuyTIQgghhDhj5ZU2HpyzmR83pXPLOTE8Pqpz\nnZUp7K4kFzbPhvgZkLUHPPyh/63QdzKEdvirXWk+HFhlJL37lsPSF2HpC+DqBa0HGD3M3iFG7/D+\nPyC/uly6Txi0HWYk09FDITC67mS1KBuyE4wYshIgOxEydsHuBWCrBIur0evrGwahHSH2fOP50X1H\nH939TEmG6+JUCTJARIAHaZIgC2EKrbVTzMpuakPXGpIz3GNnvr8CissrueOLDSzbk8mDIzpy57BY\nx/83n7beSIq3zjXGA0fEwRVTodvVdQ+h8PCDDiOMDaA4B5JX/tVLvPgZY79XCESfAzH3G0lzcLv6\nJazewcYWNfDY/VUVUFZgDJNoYt8LTpcghwd4sudwgdlhCOF0PDw8yM7OJjg4uFknUFprsrOz8fDw\nMDsUh3OGe+zM91dAbnE5N89cx6aUXF68ujvj+0c55o1tVcbKlPv/gK1z4OAmcPWGntdB3M3GsIS/\nwysIOl9mbACFmcYwiZD2DZvIWl2N92qCnDJBXro70yl6OYRoTCIjI0lNTSUzM9PsUOzOw8ODyEjn\nmwjsLPfYWe+vszuUV8qNM9awP6uY9yb04ZLurez3ZlpDxs6/enj3rzAqNgC07AajXoMeY40hFQ3B\nJ9TYRA2nTJBLKqrILa4g0FvWMxfCUVxdXYmJiTE7DGFHco9Fc3WkqJwJH63mcF4pMyf3Y3C7Bi4t\nprUxbnffMmNS3P4VUJxlHAtoA51H/1WJws+Oibmo4XQJckT1YiFpuSWSIAshhBDilEorqrj1s3hy\njhzhmysC6ep5ANIOnP7EqnIoK4TygurHwlqva+8rMCa2FR4yzvOLgHYXGglxzFAIcNAwDnEMp0uQ\nw6sXC0nPLZH1zYUQQghxUjab5r5vNpGWnMifQS/j/XPq2V/U6g7uPuDmA+6+xmP0OdWT486FoLZN\nbkJbc+TUCbIQQgghxMk8P38n67fuYFHgK3hX5cNV0+s/7tfqYpQtc/P5KyF28zmx7rBolOyWICul\nZgCXARla624naTMM+C/gCmRprc+zVzxHBXu74eZiIT2v1N5vJYQQQggHK6uswqoULme5aMeMFfv4\nacVGFvi/gl9VLtzwPbTu10BRisbOnku+zARGnuygUioAmApcrrXuClxrx1hqvy8RAZ5SC1kIIYRo\nZlJyirn4zeWc//pS1uzNPuPrLNh6kKk/r+JH35cJtmWjrv9WkmMnY7cEWWu9HMg5RZMJwHda6wPV\n7TPsFcvxwgM8ZIiFEEII0YwkHC7gmvdXkltcgUIx7sPVPDdvB6UVVX/rOuuTc3jm6+XM8XqZVjoD\ndf030GaQnaIWjZWZY5A7AK5KqaWAL/CW1vqzuhoqpaYAUwCios5+Nme4vyfLE5p3nU4hhBCi0TqS\nDNu/h8oyCGkHIR0gKBbcvM7octv3pvLC5z8xwnKQe/oofFu148XUHny8Yh9Ldmfw+rU96R0VeNrr\n7M0s5L6ZS/jc7UXaqEOoCV8bk+eE0zEzQXYB+gLDAU9glVJqtdZ6z/ENtdbTgekAcXFxZ73GZ3iA\nJxkFZZRX2nBzsecoEyGEEMJ5pOeW4Ovhgq+H64kHi3Ngxw+w5Rs4sKruC/i3NpY3DmlvJM1Hn/tF\ngLZB7gGjJFp2QvVjIuWHd9O1JIMvAaqA9calng6MZsL5d3LL+hjGTFvJHcNiuWd4e9xdrHW+dVZh\nGXfNWMI0/X+0U2mocbOh7bCz/6GIJsnMBDkVyNZaFwFFSqnlQE/ghAS5oUUEeKI1HM4vpXXQmf1r\nVQghhBB/+W3HYe6avYFQX3dmTu5PbKgPVJTAnoWw5VtIWAS2CgjpCBc8Ad2vBe9QyEmqSXbJ2mM8\n3zTLqBF8lKuXsdxyVdlf+zwCyPOOZnFRZ7I9RjBmxPkERXWDwGhIWgJLnqfDqodYGhTLV6ETeGKJ\njcU7M3h9bE+6hh9biaK4vJK7PlnOC8VP08maghr3pVGLWDgtMxPkH4F3lVIugBswAHjTEW98tNRb\nWm6JJMhCCCHEWfpq7QEe+34rnVv5kZlXxEtTP+CFdrsIPbAQyvLBJwwG3GYsjxzW49g6v2Hdja02\nraHgYK3e4kSjbFpwdc9ySHvmJ5Vz79eb6NDSl89u7k+Qj/tf53ccCR1GwK55WJe8yPVpz3FFi3Y8\nV3AlV76bzz3DO3LHsFhcrBaqbJoHv1zFA5mP0cO6H8vYz4xzhVOzZ5m32cAwIEQplQo8hVHODa31\n+1rrnUqphcAWwAZ8pLXeZq94aguvXk1PJuoJIYQQZ05rzTu/J/LGr3u4sL0/U9ssw7Lxc1yKDlK4\nx5OUNiNpPWySsUSype6hDXVSCvzCja3tiRVgv4lP4ZG5W+gTFcjHk/rh71nHkA6ljCWaO14KO37A\nZ+mLvJz/Gnf7xvLM4isYs+MCXr+uF7P+2MWN+x6gjzUJy7WfQKdLz/wHIpoNuyXIWuvx9WjzKvCq\nvWI4GVksRAghhDg7VTbNEz9uY9aaA/y7Ux73FDyNWrEHOoyksOOz3LY2lD/3FPNYu9bcGmOhodaG\nm7FiH8/O28HQ9iF8cENfvNxOk8pYLNDtauhyBWydQ+Syl/iw7A22Z//IK29dyY2WhfSz7sEy5iOj\njRA44Up6AB6uVoK93UjLlcVChBBCiL+rtKKKe2ZvZNmOFL6J+ZV+ybNRvuEw8TtoNxwf4OMeVdz/\n7WZemL+LtCMlPDm6K1bLmafJWmveXpzIm7/tYWTXMN4a3+ukE+7qZLFCz+ug2xjY8hWdlrzM9PzX\nsaHgyveN/UJUc44EWWsoKwAPv5pd4QGe0oMshBBC/E25xeX849N4dMoa1gZ9gv/BZOg7GS569pjf\nsx6uVt4Z15uIAE+mL99LWm4p74zvjafb30hqq2mtef7nnXy0Yh9j+kTy8pjuZ75SntUFek/E2n0s\nbPkai1cwdBp1ZtcSzZZzJMgzRhprp1//Tc2u8AAP9mYWmRiUEEII0bSk5ZYw5eM/uCb3Eya5LUC5\ntoYbfoDY8+tsb7EoHhvVmchAT57+aTvjPlzNxzfFEVJ7Qt0pZBeWsTwhk582pbNkdyaTBkfz5GVd\nsJxFT3QNFzfoc8PZX0c0S86RIAe3M8rMaF0zczY8wJMVCVlorVGqoUZGCSGEEM3T7kMFvPHRp7xX\n8S7R1oMQdwtc9Ay4+5723BsHRdPK35O7Z2/g6qkr+WRyP6MM3HGqbJpNKbks253B0j2ZbE3LQ2sI\n9nbjwREduXNYrPzOFg7hHAlyRB/Y9IVRYDywjbErwJOi8irySyrx96pj9qsQQgghAFi3J5Vdsx5k\nGguo9IuEq36qs7rEqVzUpSVfTRnELTPXMWbaSj66MY646CAyC8pYvieTpXsy+SMhk9ziCiwKekcF\nct+FHRjWsQVdw/0aptdYiHpykgS5r/GYtr4mQa5dC1kSZCGEEM6kpLyKzIIyKmw2KqpsVFRq43ml\njYqqY5/r/Svovv5x+qnDFPaYjM+l/wfuJ/b+1kev1gF8f+cQJn2ylgkfraF9Cx+2p+cDEOLjzvBO\nLRnWMZSh7UMI8HJryI8sxN/iHAlyy67g4mEkyN2uBo4t9dYl3O9UZwshhBDNRkZBKaPfWcHh/LJT\ntgsin0dcZjPWZRmHXMIouOYHfDvXPdb474gK9mLuHYN5eO4WjhSX88DFRi9xl1bSSywaD+dIkK2u\n0KqnkSBXq1ksJE8qWQghhHAOWmsenrOF3OIKXriqO97uVtysFlytFlysCjerBRcLhCV9Q3j8y1gr\nCsnt9U9CL34Mq8eZ9RrXJdDbjek3xjXY9YRoaM6RIIMxzCL+E6iqBKsLId7uuFktpEmpNyGEEM3B\n1jngEQBthxmlzOowe20KS3Zn8tToLkwYEHVig0NbYd59kLoW2gyBS18noEVnu4YtRGPkXAny6qmQ\nuRPCumOxKFoFeJAui4UIIYRo6la+C4seN557hxqLXvQYC+F9aqo37c8q4v9+3sE57UK4aVD0seeX\nFcCSF2HN++AZYCyc0XNczblCOBsnSpD7GI9p6yGsOwDh/rJYiBBCiCZu6xwjOe5yBXS/FrZ8A/Ez\njGQ3KBZ6XEdl12u479tDuFgUr17b46+xvlrDjh9g4aNQcAj6ToLhT4JXkKkfSQizOU+CHBgDnkGQ\nGm98AWBM1FuZlGVuXEIIIcSZ2rccfrgDogbDVdPB1QM6j4aSXNj5k5EsL30Rl6Uv8B9bO1x6XUcr\nl76AJ2QnwfwHIWmx0XE09nNo3c/sTyREo+A8CbJSxjCLtA01uyICPDicX0pFlQ3XM12yUgghhDDD\n4e3w1fUQ1BbGzzKS46M8A6DPjdDnRnbv3skPn7/F9V5riNzyPGx9CdoMhpS1YHWDkS9Bv1tPOm5Z\nCGfkXFlhRF9jDHJZIWD0INs0HM6XcchCCCGakNwU+GIMuPnAxLngGVhns9KKKu76OYO5ntfg8681\ncMdKGHw3FByEzpfBXetg4B2SHAtxHOf6PyKiL2gbHNwM0UNq1UIuJTLQy+TghBBCiHooOQJfXgPl\nRXDzQvCPPGnTV3/ZTUJGIZ/e3N9YeMOrq7E89EXPODBgIZoeJ+tBrjVRj2MXCxFCCCEavYpSmD0B\ncvbCuC+NhbBOYmVSFh+v2McNA9twXodQBwYpRNPnXD3I3iEQ0AbS4oG/FguRWshCCCEaPVsVfD8F\nDqyEMR9DzLknbZpfWsED32wmJsSbR0d1cmCQQjQPztWDDMdM1PNycyHQy1V6kIUQQjRuWhul2Hb8\nCBc/D92vOWXzp3/azuGCMt4Y2xMvN+fqCxOiIThfghwZB3kpUHAYMIZZSIIshGiulFIjlVK7lVKJ\nSqlHTtJmrFJqh1Jqu1JqlqNjFPWw8m1Y+wEM/CcMvuuUTRdsPch3G9L457BYekfVPXlPCHFqzpcg\nR/Q1HtONXuTwAE8O5kkVCyFE86OUsgLvAZcAXYDxSqkux7VpDzwKDNFadwX+5fBAxalt+RZ+fRK6\nXgUX/98pm2bkl/LY91vpHuHP3cPbOyhAIZof50uQw3qAstZM1IsI8JQxyEKI5qo/kKi13qu1Lge+\nAq44rs2twHta6yMAWusMB8coTmXvUmMhkOihcNUHYDn5r22tNQ/P3UJxeRVvXtdL6vsLcRac7/8e\nNy9o2cVYUQ9jol5BaSX5pRUmByaEEA0uAkip9Tq1el9tHYAOSqk/lVKrlVIjT3YxpdQUpVS8Uio+\nMzPTDuGKYxzaCl9NhJD2cN0X4OJ+yuaz16awZHcmj1zSiXYtfBwUpBDNk3OO3I/oC9u/B5utptTb\nwdxS/MJcTQ5MCCEczgVoDwwDIoHlSqnuWuvc4xtqracD0wHi4uK0I4N0OrkH4ItrwMMPrp9jrIx3\nEvuyinhncQI/bEpjSLtgbhoU7bg4hWimnDdBXj8TcvYSHhAMGLWQO4b5mhuXEEI0rDSgda3XkdX7\naksF1mitK4B9Sqk9GAnzOseEKE5QnGOskldZApMXgv/xnf6G/VlFvPN7Ij9sSsPVqrjlnBjuOr89\nFotycMBCND9OmiDHGY9p64mIMYbjyThkIUQztA5or5SKwUiMxwETjmvzAzAe+EQpFYIx5GKvQ6MU\nf6kogdnj4ch+uOEHY0jgcQ5kF/P27wl8vzENF4ti8uBobjsvllDfUw/BEELUn3MmyKEdwdUb0tYT\n2n0srlYlpd6EEM2O1rpSKXUX8AtgBWZorbcrpZ4F4rXWP1Ufu1gptQOoAh7UWmebF7UTs1XB3H9A\nyhq49hOIHnLM4ZScYt75PYG5G4zE+KZB0dw+rC0tfD1MCliI5ss5E2SLFcJ7Q1o8FosizN9DEmQh\nRLOktZ4PzD9u35O1nmvgvupNmEVrWPAQ7JoHI182SrpVS8kp5r0licxZn4rForhhYBvuHBZLCz9J\njIWwF+dMkAEi+sCa96GyjHB/T9JzpRayEEIIk6x4E9Z9BIPvgYG3k55bwtp9OSxPyOSnTelYLIqJ\nA9twx7BYWkpiLITdOXGC3BeqyuHwNiICPFmzL8fsiIQQQjghvWkWavEz7A8fxTs5V7H6pd9r5sX4\nurswYUAUdw5rR5i/JMZCOIrzJsiRRyfqbSA84FwO5ZdSZdNYZfavEEIIO6qyaXYdymftvhwKt//C\nHemPsbqqK5P3jsPPO5v+MUHcck4M/WOC6NzKT34vCWEC502Q/SLApyWkrSc8fARVNk1GQSmt/D3N\njkwIIUQzVFpRxaw1B5i6NIlVZYdYAAAgAElEQVSswjK6qv186/4sh91jOHjuRyxoH0VsqDdKSUIs\nhNmcN0FWyhhmkRpPeBfjz1bpuSWSIAshhPj7di80JoAHt4OAKON5tcoqG3M3pPLWbwmk55UyODaY\n54f5cOHKf2F1DcXrlnlc69fKxOCFEMdz3gQZjIl6u+fT2rMcgLTcUvq2MTkmIYQQTcuWb+C7W/96\nbXWHoLbokPYk2loxZ78Ha/KDiQ7vxKvXDmBIKwUzLgZbOUycB5IcC9HoOHmC3BeA8OJdAFLqTQgh\nxN+Tsxfm3QetB8KFT0N2Ajorgazk7ZTtXk901SEeVVXgDmQD37cAiwuU5MCNPxp1+YUQjY7dEmSl\n1AzgMiBDa93tFO36AauAcVrrOfaKp07hfQDwzNiEv2cPSZCFEELUX1WFsbCHxQJjPoSAKNbpjry6\ndjdr9w+kdZAn9w+PYXTrCqw5iZC1B7ITIC8NBt4BUQPN/gRCiJOwZw/yTOBd4LOTNVBKWYGXgUV2\njOPkPAMguH11JYsBkiALIYSovyXPQ9p6uPZTdhQH8Mr3a1m6O5MWvu48d2U3rotrjZuLxWjbogMw\nytRwhRD1Z7cEWWu9XCkVfZpmdwNzgX72iuO0IvrC3iVEhLiTJouFCCGEqI+kJbDiv9B3EmkRI7jy\ntaV4ulp55JJO3DQoGk836+mvIYRotCxmvbFSKgK4CphWj7ZTlFLxSqn4zMzMhg0koi8UHqaTd4H0\nIAshhDi9oiz4/jYI6QAjXmT2mgNUVNn4313ncPt5sZIcC9EMmJYgA/8FHtZa207XUGs9XWsdp7WO\nCw0NbdgoqifqdSeJvJIKCssqG/b6Qgghmg+t4Yc7oSQXrvmYcosHX61L4YKOLYgK9jI7OiFEAzGz\nikUc8FV1QfQQYJRSqlJr/YNDowjrBhZX2pbvAiI4mFtC+5a+Dg1BCCFEE7HmA0j4BS55FcK688vm\ndLIKy5g4SGqECtGcmNaDrLWO0VpHa62jgTnAnQ5PjgFc3CGsO2EF2wFIk2EWQggh6nJwC/z6BHS4\nBPobdY+/WJ1M6yBPzmvfwH/dFEKYym4JslJqNkb5to5KqVSl1C1KqduVUrfb6z3PWGQc3tlbsWAj\nXSbqCSGEOF55Ecy5GbyC4Yr3QCkSDhewZl8OE/q3wWKR5aGFaE7sWcVi/N9oO8lecdRLRF8sa6fT\n0ZpOem4HU0MRQgjRCC14GLITjcU9vIMBo/fYzWphbFykycEJIRqamZP0Go/qiXpDPZOlkoUQQohj\nbfsONn4OQ++DtucBUFRWyXcb0hjVPYxgH3eTAxRCNDRJkAGCYsHdn36u+2QMshBCiL8cSYb//Qsi\n4mDYozW7f9yUTkFZJTfI5DwhmiVJkMFYJjSiN51sCaTnSYIshBACqKo0lpJGwzUfg9UVAK01X6xO\nplOYL32iAs2NUQhhF5IgHxURR0TZXnLz8qiyabOjEUIIYbZlL0HqWrjsTQiMrtm9MSWXHQfzmTiw\nDdWlSoUQzYwkyEdF9MVCFR1s+8gqLDM7GiGEEGZKWw/LX4Ne10P3a4459MWqZHzcXbiyd4RJwQkh\n7E0S5KMi+gDQy5Ik45CFEMKZ2apg3n3g0xJGvnTMoSNF5czbepCrekfg427mWltCCHuSBPko3zAq\nfMLpaUmSShZCCOHM1n0MBzfBiOfBw++YQ9+uT6G80sbEgTI5T4jmTBLk2iL60lNJgiyEEE6r4DD8\n/hy0HQbdxhxzyGbTfLnmAP2jg+gY5mtKeEIIx5AEuRbX1nG0sWSQm3nQ7FCEEOIYSqm7lVJSMsHe\nFj0OlaUw6nU4bgLeH4lZJGcXc/3AKJOCE0I4iiTItUXGAeCesdnkQIQQ4gQtgXVKqW+UUiOVlE9o\neHuXwtZvYci/IKTdCYc/X5VMiI8bI7uFOT42IYRDSYJcW6te2LBgObieHen5ZkcjhBA1tNb/AdoD\nHwOTgASl1AtKqVhTA2suKsvg5weMcm5D7zvhcFpuCb/vOszYuNa4u1gdH58QwqEkQa7N3QdbSEeG\nWHdw96z1FJdXmh2REELU0Fpr4FD1VgkEAnOUUq+YGlhzsPJtyE6AUa+Bq+cJh79aewANTBggwyuE\ncAaSIB/Hpc/19NE76XhkCU//tN3scIQQAgCl1L1KqfXAK8CfQHet9R1AX2DMKU8Wp5azz6h53Ply\naH/RCYfLK23MXpvCBR1bEBnoZUKAQghHkwT5eAPugFY9edXrc36J38WPm9LMjkgIIQCCgKu11iO0\n1t9qrSsAtNY24DJzQ2vCtIYFD4HF5YSax0ct2nGIrMIyKe0mhBORBPl4Vhe4/F28KvN4I+BbHv9+\nG8nZRWZHJYQQC4Ccoy+UUn5KqQEAWuudpkXV1O2aBwmLYNij4F/3ynhfrE6mdZAn53YIdXBwQgiz\nSIJcl1Y9UEPuYXjprwxSW7hn9kbKK21mRyWEcG7TgMJarwur94kzVVYICx6GFl1hwG11Nkk4XMDq\nvTlM6N8Gq0UKhwjhLCRBPpnzHoagWN7y/pTdqRm8tmi32REJIZybqp6kB9QMrZC1js/GspchPw0u\newOsrnU2+XLNAdysFsbGRTo4OCGEmSRBPhlXT7j8bbyKUviw9SKmL9/L0t0ZZkclhHBee5VS9yil\nXKu3e4G9ZgfVZB3eAaunQu8bIGpgnU2KyiqZuz6VUd3DCPZxd3CAQggzSYJ8KtHnQN9JnJP1NZcF\nH+L+bzaTkV9qdlRCCOd0OzAYSANSgQHAFFMjaqpsNvj5PnD3hQufOWmznzanU1BWKZPzhHBCkiCf\nzkXPorxb8LrHh5SVl3LfN5ux2fTpzxNCiAaktc7QWo/TWrfQWrfUWk/QWsuftc7E5tlwYBVc9Cx4\nB9fZpKLKxuerkukU5kvfNrLCtxDOpl4JslIqVinlXv18WPWf+QLsG1oj4eEPl76Oe/ZOvuy8jhWJ\nWby/PMnsqIQQTkYp5aGU+qdSaqpSasbRzey4mpziHPj1CWg9AHpNPOGw1ppfth9ixH+Xs+NgPjef\nE4Os6i2E86lvD/JcoEop1Q6YDrQGZtktqsam82XQ5Qp6JL3P5E4VvL5oD+uTj5gdlRDCuXwOhAEj\ngGVAJFBgakRN0W9PQ0kuXPoGWI79Fbg++QjXvr+K2z5fj0UpProxjmv7yuQ8IZxRfRNkm9a6ErgK\neEdr/SDQyn5hNUKXvIpy9eDxymmE+7lxz+yN5JVUmB2VEMJ5tNNaPwEUaa0/BS7FGId8SkqpkUqp\n3UqpRKXUI3Ucn6SUylRKbare/mGH2BuH3Qthw6cw8A4I61aze29mIXd8sZ4x01aSnFPMi1d3Z+G9\nQ7mwS0vpPRbCSdW3RFCFUmo8cBMwunpf3TVxmivflnDx87j8dBdfDt7FBUvb8uh3W3hvQh/5AhVC\nOMLRf5HnKqW6AYeAFqc6QSllBd4DLsKY2LdOKfWT1nrHcU2/1lrf1dABNyqZu2HuP6BVTzj/cQCy\nCst4e3ECs9YcwN3Fwn0XdeAfQ2PwcpPqeUI4u/p+C0zGmEH9vNZ6n1IqBuPPfc6l90TY+i1R61/m\nyfO+4cklh5i19gDXD5AZzkIIu5uulAoE/gP8BPgAT5zmnP5AotZ6L4BS6ivgCuD4BLl5KzkCs8eB\nqweMm0Uxbny8OIH3lyVRWmljQv8o7hnenlBfKeUmhDDUK0Gu7m24B6D6C9pXa/2yPQNrlJSC0f+F\nqYO5Ifstfm33L57+aTttQ3wYFFv3TGghhDhbSikLkK+1PgIsB9rW89QIIKXW66Pl4Y43Ril1LrAH\n+LfWOqWONk1TVSXMuRlyU2DSPOYkwisLl5JRUMbIrmE8OLIjsaE+ZkcphGhk6lvFYqlSyk8pFQRs\nAD5USr1h39AaqaC2cP5jqD0LeL9PKm2Cvbnt83gSM2SujBDCPqpXzXvITpf/HxCtte4B/Ap8erKG\nSqkpSql4pVR8ZmamncJpYL89BUm/w6Wvs87WgQe+3UxEoCdzbh/E+zf0leRYCFGn+k7S89da5wNX\nA59prQcAF9ovrEZu4J3Qqhfeix/h03HtcHOxMOmTdWQWlJkdmRCi+fpNKfWAUqq1Uiro6Haac9Iw\nqg4dFVm9r4bWOltrffTL6yOg78kuprWerrWO01rHhYaGnslncKxNs2HVu9B/CvS9iZkr9+Pn4cKs\nfwwkLvp0PzohhDOrb4LsopRqBYwF5tkxnqbB6gJXvAvFOUSsfZ6Pb+pHVmEZ//h0HSXlVWZHJ4Ro\nnq4D/okxxGJ99RZ/mnPWAe2VUjFKKTdgHMb45RrV3+1HXQ7sbLCIzZQaD/+7F6KHwogXOJRXysJt\nh7iuX2s83axmRyeEaOTqmyA/C/wCJGmt1yml2gIJ9gurCQjrDkPugU1f0rNyK2+P682WtDzu+Woj\nVbLSnhCigWmtY+rYTjkWubo8510Y3987gW+01tuVUs8qpS6vbnaPUmq7UmozxlyTSfb8HA6RfxC+\nuh58w2DsZ2B1ZdaaZGxac8PAaLOjE0I0AUrrppXMxcXF6fj403WaOEh5MUwbBBYXuGMln6xJ55n/\n7WDykGieGt3V7OiEEI2MUmq91jruDM+9sa79WuvPzi6qM9OovotrqyiFmaMgYxf841do2ZWyyiqG\nvPQ7PSMD+HhSP7MjFEKYqL7fw/WdpBeplPpeKZVRvc1VSsnyQm5exmpM2YnwxxtMHhLD5CHRfPLn\nfmas2Gd2dEKI5qVfrW0o8DTGkAhxlNbGsIq09XD1B9DS6KhYuO0QWYXl3Dg42tz4hBBNRn3rIH+C\nsbT0tdWvJ1bvu8geQTUp7YZD92thxRvQbQz/ubQLaUdKeO7nHUQGenJx1zCzIxRCNANa67trv1ZK\nBQBfmRRO47TqXdjyFQx7DDqPrtk9c+V+YkK8GdouxMTghBBNSX3HIIdqrT/RWldWbzOBJjCF2UFG\nvACunjDv31gVvDWuNz0i/Lnnq41sTsk1OzohRPNUBMSYHUSjkfgb/PokdL4czn2wZveW1Fw2Hsjl\nxkFtsFhk1VMhRP3UN0HOVkpNVEpZq7eJQPapTlBKzagejrHtJMevV0ptUUptVUqtVEr1/LvBNxo+\nLeCiZyF5BWyahaeblY9u6keIjzu3fLqOlJxisyMUQjRxSqn/KaV+qt7mAbuB782Oq1HISoRvb4YW\nXeDKaWD561fbZ6uS8XKzMqavjAoUQtRffRPkmzFKvB0CDgLXcPqZzjOBkac4vg84T2vdHXgOmF7P\nWBqn3jdC64Gw6HEoyiLU152Zk/tRXmlj8sx15BVXmB2hEKJpew14vXp7EThXa/2IuSE1AuXF8NV4\no/zmuFng/tfCH9mFZfy0OZ2r+0Tg5+FqYpBCiKamXgmy1jpZa3251jpUa91Ca30lMOY05ywHck5x\nfGX1sqkAqzEK2DddFguMfgvKCmHRfwBo18KXD26IIzm7iNu+iKesUmokCyHO2AFgjdZ6mdb6T4y/\n7EWbG1IjsPELyNoDV38IgW2OOfR1fArllTZuGhRtTmxCiCarvj3IdbmvwaKAW4AFJzvYZJY3bdEJ\nhtwLm2fD3mUADIoN5pVrerB6bw63zIzn912HqaiymRyoEKIJ+hao/eVRVb3PeVVVGhPzIvsbE6Zr\nqayy8eXqAwyODaZ9S1+TAhRCNFVnkyA3yGwHpdT5GAnywydr06SWNz33AQiMgXn/NupxAlf1juTp\n0V3Ylp7HzTPj6f/8bzz+/VbW7svBJouKCCHqx0VrXX70RfVzNxPjMd+u/0FusrFo03F+25lBWm4J\nN0rvsRDiDJxNgnzWmZ1SqgfwEXCF1vqUk/6aDFdPuOxNyEkySr9VmzQkhrWPXcjHN8UxtH0o321I\nY+wHqzjn5d95cf5Otqfn0dQWbRFCOFRmrdXvUEpdAWSZGI+5tIY/34agttBx1AmHP1u1n3B/Dy7s\n3MLxsQkhmrxT1kFWShVQdyKsAM+zeWOlVBTwHXCD1nrP2Vyr0Yk9H3pcB38YtZEJ7QiAm4uF4Z1b\nMrxzS4rKKvlt52F+3JTOxyv28cHyvbRr4cNdUSlckvkR7m7ucPNCUFKWSAgBwO3Al0qpd6tfpwJ1\nrq7nFJL/hPQNxmJNFusxhxIOF7AyKZuHRnbExXo2/UBCCGd1ygRZa33GA7eUUrOBYUCIUioVeApw\nrb7u+8CTQDAwVRlJYOWZLsHaKF38POz5Bf73L5j08zFlhwC83V24olcEV/SKIKeonNUrFhO5/il6\nbNtIvvbEXZVgS1qGpd0wc+IXQjQqWuskYKBSyqf6daHJIZlr5TvgFQy9Jpxw6LNVybi5WLgurrUJ\ngQkhmgO7/dNaaz1ea91Ka+2qtY7UWn+stX6/OjlGa/0PrXWg1rpX9dZ8kmMAn1C4+Dk4sBI2fXny\ndtlJBM2fwqhV4+hhTSb3vOeYHjePbO1L2qI3HRevEKJRU0q9oJQK0FoXaq0LlVKBSqn/MzsuU2Ts\ngj0Lof8UY1hbLfmlFczdkMroHuEE+7ibFKAQoqmTvz3ZU6+JEDXYKPtWeFz1jYJDxkS+9/rDnkVw\n7kNw72YCzr+H+y/rywr/y4g4vIxDybvMiV0I0dhcorWuWZqzukzmiYNvncGqd8HFA/rdesKhuetT\nKS6vYtLgaMfHJYRoNiRBtieLBUb/F8qLamojU5oHi5+Ft3vDhs+g72S4dxNc8Dh4+AGglKLfNQ9i\nQ7FxzqsyeU8IAWBVStV0iSqlPAHn6yItOARbvoZe14N38DGHbDbN56uS6R0VQPdIf5MCFEI0B6cc\ngywaQGhHOOffsPwVIwHe+i2UHDEm753/OATH1nlaeFQs+8IuZMih+fy4dg9XDujo4MCFEI3Ml8Bi\npdQnGBOlJwGfmhqRGdZ8AFUVMOifJxz6IzGLvVlF/Pe6XiYEJoRoTqQH2RGG3m+UIlo7HcJ7w5Rl\ncM2MkybHR7W55D78VDHbFnxIRkGpg4IVQjRGWuuXgf8DOgMdgV+ANqc8qbkpK4T4j6Hz6Dq/Pz9b\nuZ8QH3dGdW9lQnBCiOZEEmRHcPWAG36AW36DG76H8Pr1bljaDKQstDvX6QU89cM2OwcphGgCDmOU\n3rwWuADYaW44Drbxc2OY2uATFwY5kF3M77szmNC/NW4u8qtNCHF25FvEUQLbQOt+f+8cpXAfcift\nVSp5OxezYOtB+8QmhGi0lFIdlFJPKaV2Ae8ABwCltT5fa/3uaU5vPqoqYdVUiBpU53fp56v3Y1WK\nCQOcq1NdCGEfkiA3dl2vRnsFc4/3Yp74cTu5xeWnP0cI0ZzswugtvkxrfY7W+h2gyuSYHG/HD5B3\nAAbffcKhkvIqvl6XwohuYYT5e5gQnBCiuZEEubFz9UD1ncyAirX4FKfy7LwdZkckhHCsq4GDwBKl\n1IdKqeEYk/Sch9aw8m0Ibg8dLjnh8I+b0sgvreSmQdGOj00I0SxJgtwU9LsFpSy8Fr2W7zaksWR3\nhtkRCSEcRGv9g9Z6HNAJWAL8C2ihlJqmlLrY3OgcZP8fcHAzDL7rhFVJtdbMXLmfTmG+9IsONClA\nIURzIwlyU+AXDl0up2/OPLqHuvD4d1spKK0wOyohhANprYu01rO01qOBSGAj8LDJYTnGn2+Ddyj0\nGHfCoe83prHrUAGTBkejlHN1rAsh7EcS5KZiwO2o0jze657AwfxSXl4oK+wJ4ay01ke01tO11sPN\njsXuDu+AxF+h/21GRaBakjIL+c8P2xgQE8S1ca1NClAI0RxJgtxUtB4ArXoSlfAFNw+O5ovVB1i9\nN9vsqIQQwr5WvQuuXtDvlmN2l1ZUcdesjbi7WHhrXG+sFuk9FkI0HEmQmwqljB6UzJ081DGDqCAv\nHpm7hdIK55vMLoRwEvnpsOUb6D0RvIKOOfTi/J3sPJjP62N7SuUKIUSDkwS5Kek2BryCcV//IS+N\n6c7+7GLe/HWP2VEJIYR9rPkAdBUMvPOY3Qu3HeLTVcn845wYLujU0qTghBDNmSTITYmrB/SdDLvn\nMziokPH9o/jwj71sTsk1OzIhhGhYZQUQ/wl0vhyCYmp2px4p5qE5m+kR6c9DIzuZGKAQojmTBLmp\nibsZlAXWfcSjozrRwteDf329iZScYrMjE0KIhrPhMyjLgyF/LStdUWXjntkbsWl4Z3xvWVJaCGE3\n8u3S1PhHQJfLYcNn+FnKeXdCb7ILy7hq6p9skp5kIURzUFVhLCvdZghE9K3Z/eave9hwIJcXr+5O\nm2BvEwMUQjR3kiA3RQNuh9I82PI1cdFBfHfnEDzdrFz3wSrmbz1odnRCCHF29i2H/FQYeEfNrj8S\nMpm2LIlx/Vozume4icEJIZyBJMhNUesBENYD1kwHrWnXwocf7hxC13A/7vxyA9OWJqG1NjtKIYQ4\nM4mLweoOsUaZ54yCUv799Sbahfrw1OiuJgcnhHAGkiA3RUoZvciZO42eFiDYx51Ztw5kdM9wXl64\ni0fmbqWiymZyoEIIcQYSf4PoIeDmhc2mue/rzRSUVvLuhD54ulnNjk4I4QQkQW6qqku+seaDml0e\nrlbeuq4Xd1/Qjq/jU5j0yVrySmRJaiFEE5KbAlm7a3qPpy1LYkViFk9f3pWOYb4mByeEcBaSIDdV\nrh7QdxLsWQBH9tfstlgU91/ckdeu7cnafTmMmbZSKlwIIZqOpMXGY7sLid+fwxu/7uHSHq0Y10+W\nkhZCOI4kyE1Z3C2AgpXvGrO+a7mmbySf3zKAzIIyrnzvT9YnHznt5SqqbGxPz+PrdQd44odtvLJw\nlwzTEEI4VuJv4BdBrncM98zeSESAJy9e3R2lZClpIYTjuJgdgDgL/hHGUIt1H8KmWdC6n1EWKWoQ\nRMYxsG0w3905mJtnrmP8h6t5/dqeNbO/yytt7DlcwNa0PLam5bE9LY+dhwoorzQSYm83K0XlVWQW\nlPHKNT3kl5MQwv6qKmDvMnSXK3lo7lYyCsqYe8dg/DxczY5MCOFkJEFu6i5/BzpdCskrjW3JC4AG\niytE9CG2zWDmjezPXX+4cvfsjczbkk56bim7DxVQXt077OvhQrdwfyYNjqZbhD/dwv2IDvbmrcUJ\nvLU4gTB/D+6/uKO5n1MI0fylxkNZPgeCBrNo1WEeGtmRnq0DzI5KCOGEJEFu6lw9oOuVxgZQkgsp\nayD5T0heBSvfwddWyUxlIT0glu/29aew1Q1MPiea7hH+dAv3JyrIC4vlxB7if13YnkN5pbzzeyIt\n/TyYOLCNgz+cEMKpJP4Gyspm157APi7uEmZ2REIIJyUJcnPjGQAdRhgbQHkxpK5DHVhFRNIS7k75\nkru7dobBd5/2Ukopnr+qG5mFZTz54zZCfd0Z0VV+YQkh7CRpMUT2Y3eeBatFERXkZXZEQggnJZP0\nmjs3L2h7Hgx7BG5eCF2uhEVPwJ5F9TrdxWrh3Qm96R4ZwD2zN7I+OcfOAQshGppSaqRSardSKlEp\n9cgp2o1RSmmlVJwj4wOgKAvSN0G7C9mbWURUkBduLvIrSghhDvn2cSZKwZXTIKw7zL0FMnfX6zQv\nNxdm3BRHeIAnt3waT2JGoZ0DFUI0FKWUFXgPuAToAoxXSnWpo50vcC+wxrERVktaAmhodwF7M4to\nG+JtShhCCAGSIDsfNy8YPxtcPGDWdVBcvx7hYB93Pp3cHxeL4qYZazmcX2rnQIUQDaQ/kKi13qu1\nLge+Aq6oo91zwMuAOf9zJ/4GXsFUhfViX3YRbUMlQRZCmEcSZGfkHwnjvoT8NPj2phNqKJ9MVLAX\nn0zqz5HiciZ9so6CUlmlT4gmIAJIqfU6tXpfDaVUH6C11vrnU11IKTVFKRWvlIrPzMxsuAhtNmP8\ncewFpOeVUV5po22oT8NdXwgh/iZJkJ1V6/4w+m3YtxwWPlrv07pH+jNtYl8SDhdw+xfra+omCyGa\nJqWUBXgDuP90bbXW07XWcVrruNDQ0IYL4vBWKMqE2OEkZhpDuGIlQRZCmEgSZGfWa7xRzWLdh7Du\n43qfdl6HUF4e04M/E7N5cM5mbDZtxyCFEGcpDai9TnNk9b6jfIFuwFKl1H5gIPCTQyfqJf5mPMYa\n448BGWIhhDCVlHlzdhc+Y0zWW/AQ/9/encdHWZ39H/+czGTf95ANQgj7DkJFKNQFxQWUqgXr9tOK\nuLTV2r3+rK31abW1Lq3tI1RU0NYVESqtFpdaRaug7CKEsIYEskBCEkK28/xxD2FAdjKZhe/79ZrX\nPXPPdp3czD0XZ865Dmk9oWDMcT3t68NyKa9t5LdvfEFmQhQ/vbCPjwMVkZP0CVBkjCnASYynAFft\nv9NaWwOk7b9tjHkX+L61dkmnRVj8FmQNhPhMSipWkhDlJjU2otPeXkTkUD7rQTbGzDLG7DTGrDrC\n/cYY85in7NAKzxg46WxhLvj6k5BSCC9eA9Ubj/upt44r5JqvdGXGeyU8+f7xP09EOo+1tgW4HXgD\n+Bx40Vq72hjzS2PMRP9GBzTWOosb9TgHwKlgkR6n5e1FxK98OcTiaeCCo9w/ASjyXKYBf/ZhLHI0\nUQlOZQtr4W9TnC+s42CM4d6J/Ti/Xyb3/X0Nry0rPfaTRKTTWWsXWmt7WmsLrbX3e/bdY62df5jH\njuvU3uON70FbC/Q4F4CSyjoNrxARv/NZgmytfQ84Wg2xScBs6/gISDLGdPFVPHIMqYVw5WyoXA9z\nb4K21uN6mivM8OiUIYwsSOGuF5fz73UdOLNdREJf8SKIiIPcEdTta2FH7T5N0BMRv/PnJL1jlh7a\nz2elheRg3cfChAdg3T/hrV8c99Oiwl3MvG44RZnx3PLsUj7bssuHQYpIyLDWKe9WMBbcEWzcP0FP\ni4SIiJ8FxSQ9a+0MYAbA8OHDVTLBl0bcBDvXwAePQnQyJBfAvj3QVOds99V6tntgX1379YToJJ6b\n8FMunRfJDU9/wkvTz6RHRry/WyMigayqGHZvgbPuAJzhFQCFGepBFhH/8meCfKzSQ+IvEx50hlos\nuvfL97mjITIeIuM820MO9BYAABsPSURBVARIyoPtn5Hy1wt5fcC1XLzmHK598mNevmUU2UnRnR6+\niASJ4recrWeC3oaddYQZ6Joa48egRET8myDPB243xjwPjARqrLVlfoxH9nOFw9VzoWy5szR1xP5k\nON6573Aaa+Gd+4n/eAaLohbyk4Zvcu2TLl6aPopklWsSkcMpXgSpPSC5GwAbKuvJTY4h0u3yb1wi\nctrzZZm3vwEfAr2MMduMMTcaY6YbY6Z7HrIQKAGKgZnArb6KRU6COwLyzoDMfpDcFWJSjpwcg1MJ\nY8IDcNPbhCfl8DvzCPfU3MNPnpxPQ1NL58UtIsGhuRE2vd9evQL2l3jT+GMR8T+f9SBba6ce434L\n3Oar9xc/yR4CN70Nn/yFUf/6BSOqprPg8f8w6dYHiIiM8nd0IhIotiyGlr1Q6AyvaGuzbKys48zu\nqX4OTERES02LL4S5YOTNuL+zhIou47ii5mmqHxpBW8l//B2ZiASK4rfAFQndzgKgrLaRxuY29SCL\nSEBQgiy+k5BN3vSX+fuAR2lubCBs9sXYebdAfZW/IxMRfyteBF1HQYSTEJdUOBUslCCLSCBQgiw+\nd9Hk63h22Iv8qWUibctfgEcHwau3OD1IrRqfLHLaqdkGFWvbq1eAM/4Y0CIhIhIQgqIOsgQ3Yww/\numQIdzXexQXLRvNY5vsUrVmAe/lfaYpKparrhVQUTKQ+bSgYgzFgPM9LjYvQF6ZIqGkv7+Y9Qa+O\nuEg3GfGRfgpKROQAJcjSKcLCDA9ePpBpDU1M+CKXSCYzLmw5l7Qu5ty1z9PlizlsbUtnftuZzG8d\nxRc2v/25k4fm8JMJfUjXF6dIaCheBPHZkN67fdcGTwULY4wfAxMRcShBlk4T7gpj5rXDWVlaQ0ub\nxdqxWPttVjXtIWnrIlI3zufWste5zT2f+qSeVHa7hH+a0fzu4+0sWrODH1zQm6tG5OMK0xeoSNBq\nbYGSf0PfieCVDJdU1DGiIMWPgYmIHKAEWTqV2xXGkPzkQ/amQu9vAd+C+kpY/SqxK18mdtlD3Bz2\nGJedex93FA/h/89bxctLtvKrSwcwIDfRH+GLyKkqXQL7ag4aXtHQ1ML2mka6aziViAQITdKTwBKb\nBiNughvfgDtWQvexZPz7xzyX+Tceu7Ivpbsbmfj4+9zz2ipq9jb7NpbmvfDxTHj+m7Brk2/fS+R0\nUbwITBh0H9u+a2OlM0FPFSxEJFCoB1kCV1I+XPUivH0f5v2HmVjxOV+b/iQPLa5l9oebWLiynLsv\n6sOkwdkdO25xXx0sfQoW/wHqdkCYG7Z94iy/ndW/495H5HRU/BbkngHRB35J2l/BonuaepBFJDCo\nB1kCW5gLzr0XLn8KylcS/8x53Du0kfm3jyYnOZo7XljG1JkfUbxzz6m/V2MNvPdbeGQAvHk3ZPSB\n61+H6e+DccFTF8Lmxaf+PiKnq/oq2P7ZQcMr4ECCXJCmHmQRCQxKkCU49J8MN/4LXBHw1AX037mA\nubeM4v7L+rNmey0THv0Pv1ywhnfW7mRnbeOJvXZDNbx9Pzw8AN7+FeSNgBsXwbWvQbfRTqJ845sQ\nlwFzLoO1C33TRpFQV/IOYNuXl27fXVlHTlI00REu/8QlInIIDbGQ4JHVH6a9Cy9dD6/dhqtsBd88\n/37O75fFrxeu5anFG5n1wUYA0uIi6Zed4Lkk0i87gfyUGMK8K2Ds2QEf/hE+eRKa66HPRPjq96HL\noC+/d1Ie3PAGPHc5vHA1THwMhlzdGa0WCR3FiyA6BbIHH7S7xFPiTUQkUChBluASk+KMBV70cye5\n3bGatCue5qErB/HziX35fHstq9svNXxQXElLmwUgLtLNyEzL2IQyvtL8Xwq3ziXMNrOnxySaR91B\nfN5AItxH+VElNhWuWwAvXgOv3Qb1FXDWHQeVqjpudTthy4fQ6yJw6WMop4G2Nmf8ceHZztApD2st\nJRV1XDE8z4/BiYgcTN/MEnxcbjj/fsgaCAu+AzPGwZRnScgewsjuqYzsngrWwp5ymrZ9xq7iJTSX\nLiOuejVJO3fATmi2Ll5qHcOfWyeyeWUWrCwFSomNcJEUE0FidDjJseEkRUeQnRTFzWMLSYuLhMg4\nmPoCzJsOi+51ytKddx+EHedopW1L4eMnYPWr0NoEvS+Gy2eBW4ugSIjbsQrqdx60vDTAjtp91De1\nqgdZRAKKEmQJXoO+Aem9nDJssy6AcT+GfXugbDmUrYD6nUQAmRhI7QG9xkCXgbRmDmJHTE/621h+\n1dDE7oZmdu9tZnd9k7NtaKZmbxO7GppZW1PLm2vKmftpKb+ePIDx/bLAHQGT/wIxaU4vdn0FTHoc\nXOGHj7NlH6ye5yTGpUshIg6GXQ+x6fDO/fD8VXDlHIiI6cy/nkjnik6Gr/7wy+OPK+oAVbAQkcCi\nBFmCW/bgA+OSF93rVJvI6ANF5zljibsMgsz+Ts+vhwvI9VyOxxfle7jzhWVMm7OUK4blcs8lfYmP\nCocJD0BcujOxr6EarnwGIrx6wWrLYMksWPq003OW2gMmPAiDpkJUgvOY+CyY/x147gq46nmIjO+A\nP4pIAErKg7N/9qXdG1QDWUQCkBJkCX5x6U7FieoSp3ZyeFSHvnyvrHjm3XYWj761jj+/u4EPS6p4\n6IpBzlCOr/7A6Qn++50we5JTt7lyHfz3Cfh8PrS1QtF4GDkNup/95aEYQ6+F8BiYOw1mXwpXv3xQ\nfViRUFdSUUd0uIushI793IqInAolyBIaXG5I7+mzl49wh/GD83tzdu8M7nxhOVNmfsRNY7pz1/ie\nRA673pmZ/8q34OH+TkWMyEQYcTOccSOkFh79xQdcDuHRTi/405fANa86Sb/IaaCkop6CtNiDK8yI\niPiZ6iCLnIBhXVP4x3fHMOWMfGa8V8KkP37Amu210HciXP2KU0P5ot/D99bABf/zpeS4ur6JhSvL\nuHveSq6a+RGbPD8v0/simPo8VBXD0xdC7XY/tE6k85VU1ml4hYgEHPUgi5yg2Eg3v548gPP6ZvDD\nl1cy6fH3+d55vZj21dG4CsYc9Ng9jc18vLGaxRuqWLyhis/Lap3X8CyIcNPsJcy9dZQzprnHOXDN\nXHjuSmfS4XXzIblbZzdPpNM0NreybddeJg853hkBIiKdQwmyyEk6u3cmb96ZzM9eXckD/1zL22t3\ncP9lA9hR28iHnoR4ZWkNrW2WSHcYw7sl84Pze3FmYSoDchL5eGM11876mDtfWM6Ma4Y5PzF3HQXX\nvQZzJsOsCU6SnFbk76aK+MSmqnqs1QQ9EQk8SpBFTkFKbAR/+uZQXv2slJ+/tprxD78HgDvMMDgv\nidvGFXJmYRpD8pOICj94Gd2zeqRx90V9+MWCNTyyaB3fG9/LuSNnGFz/Osy5FJ6aANfMc1YRFAkx\nJRXOEKPCdJV4E5HAogRZ5BQZY5g8NJeR3VNZsHw7vbPiOaNbCrGRx/54XT+qG2u21/LY28X07pLA\nhQO6OHdk9Yf/9w94ZiI8fZGzemDuMB+3RKRz7a+BXJCmHmQRCSxKkEU6SE5SNNPHHqNixSGMMfzq\nsv4UV9Rx14vL6ZYaS99sT43ktCK4wStJTityltqOTvHapnpdT3a2sWmqpyxBoaSinqyEqOP6z6SI\nSGfSWUnEzyLdLp64ehgT//gBN81ewoJvjyYlNsK5M7kb3PBP+PeDTmWLvdWwe4uzMEljDWAP/6Ix\naU5CndrDs/VcTyk48op/Ip1sQ2W9xh+LSEBSgiwSADISonjimmFc8cSH3PrcUubcOJJwl6cKY0I2\nXPLIl5/U1gp7dztJc0P1gW19BVRvgMpiWPdP+GzOgecYl5N0tyfPPSFrAGT07fAFVkSOxlpLSUUd\nkwZn+zsUEZEvUYIsEiAG5SXxm8kD+N6Ly7nv72v45aRjTMwLc0FsqnM5mr27oGoDVK6HqvWebTFs\neAda93ley+0s0d1lEHQZDNlDILOfs4CJiA9U1jWxp7GF7mmaoCcigUcJskgAmTw0l8/Lapn5n430\n6ZLA1BH5p/6i0cmQO9y5eGtrhd2boWwFlC2DsuWwdiF89qxzv3FBem8nac4e7CTOOUM1REM6xP4J\neoUZSpBFJPAoQRYJMD+e0Ie15Xu457VVFGXEMbxbim/eKMwFKd2dS79LnX3WQs22Awnz9mVQ/C9Y\n/lfn/sgEKPwaFJ0PRedBXMapx9G8F1r2AdZ5//2sPWSf53pLo3NpbnCeu/9y6L6WRmfSYmIuJOZA\nYp7znwWjJY0DQYlnFcnuqmAhIgFICbJIgHGFGf44dSiX/ukDpj+7lPm3jyY7qZOGOhgDSXnOpc8l\nzj5rYU8ZbFviJMvr/wVrXnPuyx4KPc+HovFOD3PYMVav31MO5Sud5Lt8JZSvgOoS37bJmzvakzB7\nJc0JOc7tuAxncmNMKrh0avS1DTvriHSHkdNZ/7ZFRE6AvgVEAlBiTDgzrx3GpY8vZtqcJbx08yii\nI1zHfqIvGONMFOw70blY6yS2696E9W/Au7+Bd38NsRlOotxzPBSMhfpK53HlK5xhHOUroX7ngddN\n7gZZA2HglANl6YwBjFcvrzm4x9cYcEc5Y6Pd0c42PMaZYBgec/B+dyQ0VEHNVqgpdXrGa0sP3F6/\nCOp2cNhKIFFJTqIcm+YkzbGpnpJ6ac6+rIGQ2dc3f+/TREllPQVpsc4KkiIiAUYJskiA6pERz6NT\nBvOt2Uv40SsrePgbg3EFQjJhjGcy3yAY+wMnES5+y0mW1y6AZc8e/PgwN6T3cYZkZA1wksus/hCV\n6PtY4zKcS84RFllpaYI9253kub7CaUtD1YFtQyXs2gSlS5zbbS3O88bcBZn3+D7+EFZSUXeg5reI\nSIBRgiwSwM7pk8n3x/fit298wertNdx+dg8uGZiN23WMoQydKTYNBn3DubS2wLaPYdMHEJ8FXQY6\nE/3ckf6O8vDcEU5PdnK3Yz/WWqf2dEMVRATXuFljzAXAo4AL+Iu19jeH3D8duA1oBeqAadbaNb6K\np6mlja279nLxQJV4E5HApARZJMDdOq6Qbqmx/OHt9dz5wnIeWbSe28b14LKhOQdqJQcKlxu6jnIu\nocYYiE5yLkHEGOMCHgfOA7YBnxhj5h+SAP/VWvu/nsdPBH4PXOCrmLZU19PaZrVIiIgELJ9+uxpj\nLjDGfGGMKTbG/Pgw9+cbY94xxnxmjFlhjLnQl/GIBCNjDBcN7MLC74zhiWuGER/l5oevrGDcb9/l\n2Y82s6+l1d8hSmAbARRba0ustU3A88Ak7wdYa2u9bsZyxCUaO8aGCk8Fi3SVeBORwOSzBNmr12IC\n0BeYaow5dFbL3cCL1tohwBTgT76KRyTYhYUZzu+XxYLbR/PU9WeQkRDJ3fNWMfbBd3nqg400NitR\nlsPKAbZ63d7m2XcQY8xtxpgNwIPAdw73QsaYacaYJcaYJRUVFScdUEl7gqweZBEJTL7sQT5mrwVO\nL8X+WRqJwHYfxiMSEowxfK13BnNvGcWzN44kPzWGXyxYw+gH3mHGexuo39fi7xAlCFlrH7fWFgI/\nwum8ONxjZlhrh1trh6enp5/0e5VU1JEeH0lClBadEZHA5MsxyIfrtRh5yGPuBd40xnwb52e9cw/3\nQsaYacA0gPz8DlhZTCQEGGMYXZTG6KI0/ltSxR/eLuZ/Fq7l8Xc2cEa3ZPplJ9I/J5H+OQlkJURh\ntEDG6aoUyPO6nevZdyTPA3/2ZUAbKuq0QIiIBDR/T9KbCjxtrX3IGHMmMMcY099a2+b9IGvtDGAG\nwPDhw306Nk4kGI3snsrI7ql8umUXz360mZXbanh77U7aPJ+W1NgI+uUk0i87gf7ZTtKcnxKjpPn0\n8AlQZIwpwEmMpwBXeT/AGFNkrV3vuXkRsB4fKqmsZ0L/Lr58CxGRU+LLBPl4ei1uxDNT2lr7oTEm\nCkgDdiIiJ2xofjJD85MBaGhq4fOyPazeXsOq0hpWldYy870SWjxZc3yUuz1h7pfjbLunxwVGrWXp\nMNbaFmPM7cAbOGXeZllrVxtjfgkssdbOB243xpwLNAO7gOt8FU91fRO7G5op1PhjEQlgvkyQj9lr\nAWwBzgGeNsb0AaKAk5/5ISLtYiLcDOuazLCuye379rW0sq68zkmat9ewsrSWOR9tZl+L86NNdLiL\nPl3inaEZnsS5KCOeCHeAlZOTE2KtXQgsPGTfPV7Xv9tZsZRU1AGaoCcigc1nCfJx9lrcBcw0xtyJ\nM2HvemuthlCI+Eik28WA3EQG5B5Yxa6ltY0NFfWsKq1h9fZaVm2vYe6npcz+cDMAEa4wembFMSAn\nkUmDcxhZkKKhGXLS2itYpKnEm4gELp+OQT6OXos1wFm+jEFEjs7tCqNXVjy9suL5umdF5rY2y+bq\nBs/wjFpWb6/h7yvK+NvHW+mXncANZxVw8aAuRLpd/g1egs6GyjrCXYbc5Gh/hyIickT+nqQnIgEo\nLMxQkBZLQVps+3LAe5tambeslFnvb+Sul5bz63+s5ZqvdOWbX8knLS5Al5KWgFNSUU+31NjAWi5d\nROQQSpBF5LhER7iYOiKfKWfk8X5xJbPe38jDi9bx+LvFTBqUzQ2jC+jTJeHYLySntZKKOnpkaHiF\niAQ2JcgickKMMYwpSmdMUTobKup46oONvLK0lJeWbmNUYSo3nFXA2b0zCPNUw2hts+xqaKKqronK\nun2eSxNVdfuoqmtiV0MTGQmRFKTF0d3Ta52bHK0exhDU3NrG5qoGxvfL8ncoIiJHpQRZRE5aYXoc\nv7p0AN8f34vnP9nKM4s38a3ZS8hNjiY2wk1V/T6q65va6zF7c4UZUmMjSIoJ56OSKmobD6wAGO4y\n5KfEOElzemz7cI/uabGkx0dqkmCQ2lrdQEub1SIhIhLwlCCLyClLiolg+thCbhxdwBury3n101Lc\nLsOwbsmkxUaQGhdJWlwkqXERpMVFkBbnLDO8v5fZWsuuhmY2VtZRUlHPxsr69u176ytoajmwdlBm\nQiTDu6a0l7Drm51AuHqbg0J7BYt0DbEQkcCmBFlEOky4K4yLB2a3T+w7XsYYUmIjSIlNYVjXlIPu\na2uzbK/Zy8bKeop31rFs626WbNrF6yvLAKd286C8RIZ1TWZ41xSG5ieTGBPeYW2SjlNS6dRA1iIh\nIhLolCCLSEALCzPkJseQmxzDmKL09v3lNY0s2VzNkk27+HTLLv733yW0tm0AoCgjjuHdkumXnUiv\nrHh6ZsaTGK2k2d9KKupJiY0gKSbC36GIiByVEmQRCUpZiVEH9VY3NLWwbOtulm7axdItu3jdU7d5\nv+zEKHp66j33ynS2helxRIWrlnNnKamo1/hjEQkKSpBFJCTERLgZVZjGqMI0wBnXvL2mkS/Ka/mi\nvM7Z7qhjcXEVTa3OmGZXmKFbagy9suIpSIula0oseSkxdE2NISshqn2MtHSMkso6zumd6e8wRESO\nSQmyiIQkYww5SdHkJEVztldS5pQaq2dt+R7Wle9hbfke1myv5c3VO2jxKrcR4QojNyWa/JQYuqbE\nkJcS41xPjSU/JYboCPU8n4iahmYq65rorvHHIhIElCCLyGkl3BVGj4x4emTEw8AD+1ta2yiraWRz\nVQNbqhvYXF3P1mrn+tLNu9jjVYbupjEF/Oyivn6IPnht8EzQUwULEQkGSpBFRAC3K4w8T0/xoay1\n1Oxtbk+eu6WqF/RE5afE8NvLBzI4L8nfoYiIHJMSZBGRYzDGkBTjVF8YpATvpKTFRXLF8Dx/hyEi\nclxUXV9ERERExIsSZBERERERL0qQRURERES8KEEWEREREfGiBFlERERExIsSZBERERERL0qQRURE\nRES8KEEWEREREfGiBFlERERExIux1vo7hhNijKkANp/EU9OAyg4OJ1CobcEplNsGod2+k21bV2tt\nekcH4w86Fx+W2hac1Lbg5NPzcNAlyCfLGLPEWjvc33H4gtoWnEK5bRDa7QvltvlaKP/t1LbgpLYF\nJ1+3TUMsRERERES8KEEWEREREfFyOiXIM/wdgA+pbcEplNsGod2+UG6br4Xy305tC05qW3DyadtO\nmzHIIiIiIiLH43TqQRYREREROSYlyCIiIiIiXkI+QTbGXGCM+cIYU2yM+bG/4+loxphNxpiVxphl\nxpgl/o7nVBhjZhljdhpjVnntSzHG/MsYs96zTfZnjCfrCG271xhT6jl2y4wxF/ozxpNljMkzxrxj\njFljjFltjPmuZ3/QH7ujtC0kjl1nCuVzcSidh0Hn4mD9POtc3LHHLqTHIBtjXMA64DxgG/AJMNVa\nu8avgXUgY8wmYLi1NugLgRtjvgrUAbOttf09+x4Eqq21v/F8qSZba3/kzzhPxhHadi9QZ639nT9j\nO1XGmC5AF2vtp8aYeGApcClwPUF+7I7StisJgWPXWUL9XBxK52HQuThY6VzcsUK9B3kEUGytLbHW\nNgHPA5P8HJMcgbX2PaD6kN2TgGc815/B+UAEnSO0LSRYa8ustZ96ru8BPgdyCIFjd5S2yYnRuTiI\n6FwcnHQu7lihniDnAFu9bm8j9L7cLPCmMWapMWaav4PxgUxrbZnnejmQ6c9gfOB2Y8wKz89+Qfez\n16GMMd2AIcB/CbFjd0jbIMSOnY+F+rk41M/DEGKf58MIqc+zzsWnLtQT5NPBaGvtUGACcJvn56OQ\nZJ3xQKE0JujPQCEwGCgDHvJvOKfGGBMHvALcYa2t9b4v2I/dYdoWUsdOTtlpcx6G4P88H0ZIfZ51\nLu4YoZ4glwJ5XrdzPftChrW21LPdCbyK81NmKNnhGXu0fwzSTj/H02GstTusta3W2jZgJkF87Iwx\n4TgnreestXM9u0Pi2B2ubaF07DpJSJ+LT4PzMITI5/lwQunzrHNxxx27UE+QPwGKjDEFxpgIYAow\n388xdRhjTKxnsDrGmFhgPLDq6M8KOvOB6zzXrwNe82MsHWr/CcvjMoL02BljDPAk8Lm19vdedwX9\nsTtS20Ll2HWikD0XnybnYQiBz/ORhMrnWefijj12IV3FAsBT8uMRwAXMstbe7+eQOowxpjtObwWA\nG/hrMLfPGPM3YByQBuwAfg7MA14E8oHNwJXW2qCbYHGEto3D+VnIApuAm73GiQUNY8xo4D/ASqDN\ns/unOOPDgvrYHaVtUwmBY9eZQvVcHGrnYdC5mCD9POtc3LHHLuQTZBERERGRExHqQyxERERERE6I\nEmQRERERES9KkEVEREREvChBFhERERHxogRZRERERMSLEmQRERERES9KkEVEREREvPwfvU3KY9U5\ndRgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "RP-D_0jDlByC",
        "colab_type": "code",
        "outputId": "d8d4b90b-b819-49f4-8693-8a326e84aa3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "custom_cnn.evaluate(x_test, y_test)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1694/1694 [==============================] - 3s 2ms/sample - loss: 1.0719 - acc: 0.5962\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0719019966958687, 0.596222]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "YATtTFvMdLmr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 使用 MobileNet"
      ]
    },
    {
      "metadata": {
        "id": "6rnrgTTKlqhf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9cce6cc4-5ff0-420e-c9e7-dd02d6675792"
      },
      "cell_type": "code",
      "source": [
        "images, labels = load_data()\n",
        "(x_train, y_train), (x_test, y_test), datagen = preprocess(images, labels, image_size=(224, 224))\n",
        "\n",
        "print((x_train.shape), (y_train.shape))\n",
        "print((x_test.shape), (y_test.shape))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1976, 224, 224, 3) (1976, 5)\n",
            "(847, 224, 224, 3) (847, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zekNnXKklJbp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "\n",
        "def build_mobilenet():\n",
        "    input = layers.Input(x_train.shape[1:])\n",
        "    base_model = MobileNetV2(input_tensor=input, weights='imagenet', include_top=True)\n",
        "    \n",
        "    model = tf.keras.Sequential([\n",
        "        base_model,\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    for layer in model.layers[:249]:\n",
        "        layer.trainable = True\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nHG4vjnwmRAo",
        "colab_type": "code",
        "outputId": "c2d449cc-fd61-4afe-d023-fe5d277a9dd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "cell_type": "code",
      "source": [
        "build_mobilenet().summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "mobilenetv2_1.00_224 (Model) (None, 1000)              3538984   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 5005      \n",
            "=================================================================\n",
            "Total params: 3,543,989\n",
            "Trainable params: 3,509,877\n",
            "Non-trainable params: 34,112\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9XeLmma3mCLm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mobilenet = build_mobilenet()\n",
        "optimizer = tf.keras.optimizers.Adam(lr=1e-3)\n",
        "mobilenet.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jz0DXOv5mJbx",
        "colab_type": "code",
        "outputId": "bd6327a2-83b4-4cde-9c22-4497ad7d0f5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3250
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "history = mobilenet.fit(\n",
        "    datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "    epochs=50,\n",
        "    validation_data=(x_test, y_test),\n",
        "    verbose=1,\n",
        "    steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "    callbacks=get_callbacks('mobilenet')\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/50\n",
            "847/847 [==============================] - 4s 5ms/sample - loss: 1.5880 - acc: 0.3176\n",
            "31/31 [==============================] - 42s 1s/step - loss: 1.5532 - acc: 0.6058 - val_loss: 1.5860 - val_acc: 0.3176\n",
            "Epoch 2/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.5618 - acc: 0.3530\n",
            "31/31 [==============================] - 30s 982ms/step - loss: 1.5105 - acc: 0.6579 - val_loss: 1.5597 - val_acc: 0.3530\n",
            "Epoch 3/50\n",
            "847/847 [==============================] - 3s 3ms/sample - loss: 1.5625 - acc: 0.3070\n",
            "\n",
            "Epoch 00003: val_loss improved from inf to 1.55940, saving model to ./weights/weights.mobilenet-03-1.48-1.56.hdf5\n",
            "31/31 [==============================] - 37s 1s/step - loss: 1.4805 - acc: 0.6058 - val_loss: 1.5594 - val_acc: 0.3070\n",
            "Epoch 4/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.6013 - acc: 0.2586\n",
            "31/31 [==============================] - 30s 955ms/step - loss: 1.4585 - acc: 0.5673 - val_loss: 1.5973 - val_acc: 0.2586\n",
            "Epoch 5/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.5416 - acc: 0.3447\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "31/31 [==============================] - 34s 1s/step - loss: 1.4180 - acc: 0.7014 - val_loss: 1.5387 - val_acc: 0.3447\n",
            "Epoch 6/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.5155 - acc: 0.4569\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.55940 to 1.51246, saving model to ./weights/weights.mobilenet-06-1.39-1.51.hdf5\n",
            "31/31 [==============================] - 31s 1s/step - loss: 1.3891 - acc: 0.7642 - val_loss: 1.5125 - val_acc: 0.4569\n",
            "Epoch 7/50\n",
            "847/847 [==============================] - 3s 3ms/sample - loss: 1.5029 - acc: 0.4911\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3747 - acc: 0.7814 - val_loss: 1.5002 - val_acc: 0.4911\n",
            "Epoch 8/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.5242 - acc: 0.4475\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3651 - acc: 0.7961 - val_loss: 1.5205 - val_acc: 0.4475\n",
            "Epoch 9/50\n",
            "847/847 [==============================] - 3s 3ms/sample - loss: 1.5332 - acc: 0.4333\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.51246\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3555 - acc: 0.8158 - val_loss: 1.5296 - val_acc: 0.4333\n",
            "Epoch 10/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.5010 - acc: 0.4876\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3489 - acc: 0.8244 - val_loss: 1.4962 - val_acc: 0.4876\n",
            "Epoch 11/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.4940 - acc: 0.5041\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3464 - acc: 0.8229 - val_loss: 1.4891 - val_acc: 0.5041\n",
            "Epoch 12/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.4867 - acc: 0.5171\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.51246 to 1.48220, saving model to ./weights/weights.mobilenet-12-1.35-1.48.hdf5\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3494 - acc: 0.8188 - val_loss: 1.4822 - val_acc: 0.5171\n",
            "Epoch 13/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.4805 - acc: 0.5336\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3431 - acc: 0.8345 - val_loss: 1.4761 - val_acc: 0.5336\n",
            "Epoch 14/50\n",
            "847/847 [==============================] - 3s 3ms/sample - loss: 1.4776 - acc: 0.5419\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3414 - acc: 0.8386 - val_loss: 1.4734 - val_acc: 0.5419\n",
            "Epoch 15/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.4720 - acc: 0.5549\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.48220 to 1.46823, saving model to ./weights/weights.mobilenet-15-1.34-1.47.hdf5\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3422 - acc: 0.8295 - val_loss: 1.4682 - val_acc: 0.5549\n",
            "Epoch 16/50\n",
            "847/847 [==============================] - 3s 3ms/sample - loss: 1.4686 - acc: 0.5643\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3433 - acc: 0.8264 - val_loss: 1.4650 - val_acc: 0.5643\n",
            "Epoch 17/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.4663 - acc: 0.5702\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3392 - acc: 0.8345 - val_loss: 1.4628 - val_acc: 0.5702\n",
            "Epoch 18/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.4615 - acc: 0.5832\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.46823 to 1.45825, saving model to ./weights/weights.mobilenet-18-1.34-1.46.hdf5\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3405 - acc: 0.8315 - val_loss: 1.4582 - val_acc: 0.5832\n",
            "Epoch 19/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.4592 - acc: 0.5868\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3418 - acc: 0.8300 - val_loss: 1.4547 - val_acc: 0.5868\n",
            "Epoch 20/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.4557 - acc: 0.5915\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3415 - acc: 0.8300 - val_loss: 1.4512 - val_acc: 0.5915\n",
            "Epoch 21/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.4547 - acc: 0.5939\n",
            "\n",
            "Epoch 00021: val_loss improved from 1.45825 to 1.45024, saving model to ./weights/weights.mobilenet-21-1.33-1.45.hdf5\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3346 - acc: 0.8482 - val_loss: 1.4502 - val_acc: 0.5939\n",
            "Epoch 22/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.4525 - acc: 0.5986\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3379 - acc: 0.8335 - val_loss: 1.4482 - val_acc: 0.5986\n",
            "Epoch 23/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.4509 - acc: 0.6045\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3380 - acc: 0.8401 - val_loss: 1.4467 - val_acc: 0.6045\n",
            "Epoch 24/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.4497 - acc: 0.6033\n",
            "\n",
            "Epoch 00024: val_loss improved from 1.45024 to 1.44585, saving model to ./weights/weights.mobilenet-24-1.33-1.45.hdf5\n",
            "31/31 [==============================] - 33s 1s/step - loss: 1.3348 - acc: 0.8411 - val_loss: 1.4459 - val_acc: 0.6033\n",
            "Epoch 25/50\n",
            "847/847 [==============================] - 3s 3ms/sample - loss: 1.4447 - acc: 0.6116\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3354 - acc: 0.8391 - val_loss: 1.4414 - val_acc: 0.6116\n",
            "Epoch 26/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.4405 - acc: 0.6246\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3308 - acc: 0.8532 - val_loss: 1.4374 - val_acc: 0.6246\n",
            "Epoch 27/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.4397 - acc: 0.6257\n",
            "\n",
            "Epoch 00027: val_loss improved from 1.44585 to 1.43677, saving model to ./weights/weights.mobilenet-27-1.33-1.44.hdf5\n",
            "31/31 [==============================] - 33s 1s/step - loss: 1.3335 - acc: 0.8467 - val_loss: 1.4368 - val_acc: 0.6257\n",
            "Epoch 28/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.4384 - acc: 0.6281\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3341 - acc: 0.8411 - val_loss: 1.4355 - val_acc: 0.6281\n",
            "Epoch 29/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.4359 - acc: 0.6340\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3373 - acc: 0.8340 - val_loss: 1.4331 - val_acc: 0.6340\n",
            "Epoch 30/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.4324 - acc: 0.6423\n",
            "\n",
            "Epoch 00030: val_loss improved from 1.43677 to 1.42976, saving model to ./weights/weights.mobilenet-30-1.33-1.43.hdf5\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3321 - acc: 0.8462 - val_loss: 1.4298 - val_acc: 0.6423\n",
            "Epoch 31/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.4283 - acc: 0.6482\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3268 - acc: 0.8543 - val_loss: 1.4259 - val_acc: 0.6482\n",
            "Epoch 32/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.4218 - acc: 0.6647\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3277 - acc: 0.8563 - val_loss: 1.4198 - val_acc: 0.6647\n",
            "Epoch 33/50\n",
            "847/847 [==============================] - 3s 3ms/sample - loss: 1.4154 - acc: 0.6765\n",
            "\n",
            "Epoch 00033: val_loss improved from 1.42976 to 1.41364, saving model to ./weights/weights.mobilenet-33-1.33-1.41.hdf5\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3313 - acc: 0.8431 - val_loss: 1.4136 - val_acc: 0.6765\n",
            "Epoch 34/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.4088 - acc: 0.6895\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3321 - acc: 0.8446 - val_loss: 1.4074 - val_acc: 0.6895\n",
            "Epoch 35/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.4053 - acc: 0.6989\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3280 - acc: 0.8502 - val_loss: 1.4040 - val_acc: 0.6989\n",
            "Epoch 36/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.4012 - acc: 0.7072\n",
            "\n",
            "Epoch 00036: val_loss improved from 1.41364 to 1.40014, saving model to ./weights/weights.mobilenet-36-1.33-1.40.hdf5\n",
            "31/31 [==============================] - 33s 1s/step - loss: 1.3270 - acc: 0.8522 - val_loss: 1.4001 - val_acc: 0.7072\n",
            "Epoch 37/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.3985 - acc: 0.7096\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3290 - acc: 0.8482 - val_loss: 1.3976 - val_acc: 0.7096\n",
            "Epoch 38/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.3932 - acc: 0.7190\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3276 - acc: 0.8512 - val_loss: 1.3925 - val_acc: 0.7190\n",
            "Epoch 39/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.3890 - acc: 0.7308\n",
            "\n",
            "Epoch 00039: val_loss improved from 1.40014 to 1.38857, saving model to ./weights/weights.mobilenet-39-1.32-1.39.hdf5\n",
            "31/31 [==============================] - 33s 1s/step - loss: 1.3230 - acc: 0.8598 - val_loss: 1.3886 - val_acc: 0.7308\n",
            "Epoch 40/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.3866 - acc: 0.7367\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3299 - acc: 0.8416 - val_loss: 1.3863 - val_acc: 0.7367\n",
            "Epoch 41/50\n",
            "847/847 [==============================] - 3s 3ms/sample - loss: 1.3833 - acc: 0.7414\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3270 - acc: 0.8492 - val_loss: 1.3832 - val_acc: 0.7414\n",
            "Epoch 42/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.3800 - acc: 0.7450\n",
            "\n",
            "Epoch 00042: val_loss improved from 1.38857 to 1.38004, saving model to ./weights/weights.mobilenet-42-1.32-1.38.hdf5\n",
            "31/31 [==============================] - 33s 1s/step - loss: 1.3244 - acc: 0.8558 - val_loss: 1.3800 - val_acc: 0.7450\n",
            "Epoch 43/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.3766 - acc: 0.7509\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3206 - acc: 0.8659 - val_loss: 1.3768 - val_acc: 0.7509\n",
            "Epoch 44/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.3728 - acc: 0.7615\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3227 - acc: 0.8558 - val_loss: 1.3728 - val_acc: 0.7615\n",
            "Epoch 45/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.3697 - acc: 0.7662\n",
            "\n",
            "Epoch 00045: val_loss improved from 1.38004 to 1.36998, saving model to ./weights/weights.mobilenet-45-1.32-1.37.hdf5\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3214 - acc: 0.8588 - val_loss: 1.3700 - val_acc: 0.7662\n",
            "Epoch 46/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.3676 - acc: 0.7721\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3216 - acc: 0.8558 - val_loss: 1.3679 - val_acc: 0.7721\n",
            "Epoch 47/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.3662 - acc: 0.7710\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3225 - acc: 0.8548 - val_loss: 1.3668 - val_acc: 0.7710\n",
            "Epoch 48/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.3623 - acc: 0.7828\n",
            "\n",
            "Epoch 00048: val_loss improved from 1.36998 to 1.36254, saving model to ./weights/weights.mobilenet-48-1.32-1.36.hdf5\n",
            "31/31 [==============================] - 33s 1s/step - loss: 1.3212 - acc: 0.8588 - val_loss: 1.3625 - val_acc: 0.7828\n",
            "Epoch 49/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.3604 - acc: 0.7828\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3159 - acc: 0.8694 - val_loss: 1.3599 - val_acc: 0.7828\n",
            "Epoch 50/50\n",
            "847/847 [==============================] - 2s 3ms/sample - loss: 1.3579 - acc: 0.7863\n",
            "31/31 [==============================] - 32s 1s/step - loss: 1.3230 - acc: 0.8502 - val_loss: 1.3567 - val_acc: 0.7863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fGNLyCiwvGuU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_train_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1S_xsmR5necV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 使用 Xception"
      ]
    },
    {
      "metadata": {
        "id": "a-4OfkVGng3J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e211e24d-b6e2-487a-844f-b313ad23be79"
      },
      "cell_type": "code",
      "source": [
        "images, labels = load_data()\n",
        "(x_train, y_train), (x_test, y_test), datagen = preprocess(images, labels, image_size=(299, 299), data_augmentation='idg')\n",
        "\n",
        "print((x_train.shape), (y_train.shape))\n",
        "print((x_test.shape), (y_test.shape))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1976, 299, 299, 3) (1976, 5)\n",
            "(847, 299, 299, 3) (847, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CPnZKsD-nw8s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.xception import Xception\n",
        "\n",
        "\n",
        "def build_xception():\n",
        "    input = layers.Input(x_train.shape[1:])\n",
        "    base_model = Xception(include_top=True, input_tensor=input, weights='imagenet')\n",
        "    \n",
        "    model = tf.keras.Sequential([\n",
        "        base_model,\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    for layer in model.layers[:249]:\n",
        "        layer.trainable = True\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rPoSd0imopH9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "87a49eaa-39ad-4924-8bb6-e9960b1ed898"
      },
      "cell_type": "code",
      "source": [
        "build_xception().summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "xception (Model)             (None, 1000)              22910480  \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 5005      \n",
            "=================================================================\n",
            "Total params: 22,915,485\n",
            "Trainable params: 22,860,957\n",
            "Non-trainable params: 54,528\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gYQFQR-fosHz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "xception = build_xception()\n",
        "optimizer = tf.keras.optimizers.Adam(lr=1e-3)\n",
        "xception.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CcT2QOBBov0T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "outputId": "9d64d042-622d-4f8a-b156-ccfb9a9a98b0"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "history = xception.fit_generator(\n",
        "    datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "    epochs=50,\n",
        "    validation_data=(x_test, y_test),\n",
        "    verbose=1,\n",
        "    steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "    callbacks=get_callbacks('xception')\n",
        ")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "847/847 [==============================] - 21s 25ms/sample - loss: 1.5972 - acc: 0.2739\n",
            "124/124 [==============================] - 195s 2s/step - loss: 1.5380 - acc: 0.6037 - val_loss: 1.5972 - val_acc: 0.2739\n",
            "Epoch 2/50\n",
            "847/847 [==============================] - 18s 22ms/sample - loss: 1.5693 - acc: 0.2916\n",
            "124/124 [==============================] - 187s 2s/step - loss: 1.4760 - acc: 0.5374 - val_loss: 1.5691 - val_acc: 0.2916\n",
            "Epoch 3/50\n",
            " 39/124 [========>.....................] - ETA: 1:54 - loss: 1.4127 - acc: 0.6218"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-4ed259667652>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'xception'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m       \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1189\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "q5DLlorg9-YT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_train_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-to_O9brlwSE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 提交"
      ]
    },
    {
      "metadata": {
        "id": "VjHu6E8wBf9M",
        "colab_type": "code",
        "outputId": "d66d3ca6-8b3b-4205-a1c6-8dbfd926d69a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "recover_model('weights.mobilenet-30-1.31-1.39').evaluate(x_test, y_test)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "847/847 [==============================] - 4s 5ms/sample - loss: 1.3646 - acc: 0.8076\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3646023290357172, 0.8075561]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "cEtkAFCyFM7B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ids = load_test_ids()\n",
        "model = recover_model('weights.mobilenet-30-1.31-1.39')\n",
        "# model = custom_cnn\n",
        "result = evaluate(ids, image_size=(224, 224))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eyGlgxhKHpnu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred = np.argmax(result, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vGg-r8kyHRsd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "submission = to_submit(ids, pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kaH1mFlZIcfI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.savetxt('submission.csv', submission, delimiter=',', fmt='%s')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_d4WnuJL7HM3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}